{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fb2b346-104f-4c59-9f24-ef955d00d3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports\n",
    "# Basic OS, date/time, and numerical libraries\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "# Libraries for data handling and scientific computing\n",
    "import xarray as xr\n",
    "import dask.array as da # For handling large arrays that don't fit in memory\n",
    "\n",
    "# PyTorch libraries for deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F # For functions like F.pad\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# PyTorch Lightning for streamlining training\n",
    "import lightning.pytorch as pl\n",
    "\n",
    "# Plotting library\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pandas for data manipulation (e.g., creating submission CSV)\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70e1f3a3-b5e7-4d49-a588-1e1b836b99d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Configuration\n",
    "# Main configuration dictionary for the experiment\n",
    "\n",
    "# NOTE: You MUST change the 'path' in config['data'] to the correct location \n",
    "# of your 'processed_data_cse151b_v2_corrupted_ssp245.zarr' file.\n",
    "config = {\n",
    "    \"data\": {\n",
    "        \"path\": \"processed_data_cse151b_v2_corrupted_ssp245/processed_data_cse151b_v2_corrupted_ssp245.zarr\",\n",
    "        \"input_vars\": [\"CO2\", \"SO2\", \"CH4\", \"BC\", \"rsdt\"], # Input climate forcing variables\n",
    "        \"output_vars\": [\"tas\", \"pr\"], # Target variables: surface air temperature and precipitation\n",
    "        \"target_member_id\": 0, # Ensemble member to use for target variables\n",
    "        \"train_ssps\": [\"ssp126\", \"ssp370\", \"ssp585\"], # SSP scenarios for training\n",
    "        \"test_ssp\": \"ssp245\",  # SSP scenario for testing (held-out)\n",
    "        \"test_months\": 360,   # Number of months for the test split (last 10 years)\n",
    "        \"batch_size\": 64,     # Batch size for training and evaluation\n",
    "        \"num_workers\": 4,     # Number of workers for DataLoader\n",
    "    },\n",
    "    \"model_unet\": { # Configuration specific to U-Net\n",
    "        \"type\": \"unet\",\n",
    "        \"init_features\": 64, # Number of features in the first convolutional layer of U-Net\n",
    "        \"bilinear\": True,    # Whether to use bilinear upsampling in U-Net's decoder\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"lr\": 1e-3, # Learning rate\n",
    "        # Add other training parameters like weight_decay if needed\n",
    "    },\n",
    "    \"trainer\": {\n",
    "        \"max_epochs\": 20,         # Maximum number of training epochs\n",
    "        \"accelerator\": \"auto\",    # Auto-detect accelerator (CPU, GPU, TPU)\n",
    "        \"devices\": \"auto\",        # Auto-detect number of devices\n",
    "        \"precision\": 32,          # Training precision (e.g., 16 for mixed-precision)\n",
    "        \"deterministic\": True,    # For reproducibility\n",
    "        \"num_sanity_val_steps\": 0,# Number of sanity check validation steps before training\n",
    "        # \"logger\": True, # Example: WandbLogger(...) or TensorBoardLogger(...)\n",
    "        # \"callbacks\": [] # Example: [ModelCheckpoint(...), EarlyStopping(...)]\n",
    "    },\n",
    "    \"seed\": 42, # Seed for reproducibility\n",
    "}\n",
    "\n",
    "# Set seed for PyTorch Lightning, PyTorch, NumPy, and Python's random module\n",
    "pl.seed_everything(config[\"seed\"], workers=True) \n",
    "\n",
    "# Suggestion from PyTorch for Tensor Core utilization on compatible GPUs\n",
    "if torch.cuda.is_available() and torch.cuda.get_device_capability()[0] >= 7: # Check for Volta architecture or newer\n",
    "    torch.set_float32_matmul_precision('medium') # or 'high'\n",
    "    print(\"Set torch.set_float32_matmul_precision('medium') for Tensor Core utilization.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b8df60e-21e9-4e7b-a414-e1b5afde2aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Latitude Weights Utility\n",
    "\n",
    "def get_lat_weights(latitude_values):\n",
    "    \"\"\"\n",
    "    Computes cosine-based area weights for each latitude.\n",
    "    This accounts for the Earth's curvature, giving more weight to\n",
    "    grid cells near the equator for global metrics.\n",
    "\n",
    "    Args:\n",
    "        latitude_values (np.array): Array of latitude values in degrees.\n",
    "\n",
    "    Returns:\n",
    "        np.array: Normalized latitude weights.\n",
    "    \"\"\"\n",
    "    lat_rad = np.deg2rad(latitude_values) # Convert degrees to radians\n",
    "    weights = np.cos(lat_rad)             # Cosine of latitude\n",
    "    return weights / np.mean(weights)     # Normalize by the mean weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "032abb3c-54cd-417d-93f8-9fe55d3a4892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Normalizer Class\n",
    "\n",
    "class Normalizer:\n",
    "    \"\"\"\n",
    "    Handles Z-score normalization for input and output data.\n",
    "    (data - mean) / std\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.mean_in, self.std_in = None, None   # Statistics for input data\n",
    "        self.mean_out, self.std_out = None, None # Statistics for output data\n",
    "\n",
    "    def set_input_statistics(self, mean, std):\n",
    "        \"\"\"Sets the mean and standard deviation for input data.\"\"\"\n",
    "        self.mean_in = mean\n",
    "        self.std_in = std\n",
    "\n",
    "    def set_output_statistics(self, mean, std):\n",
    "        \"\"\"Sets the mean and standard deviation for output data.\"\"\"\n",
    "        self.mean_out = mean\n",
    "        self.std_out = std\n",
    "\n",
    "    def normalize(self, data, data_type):\n",
    "        \"\"\"\n",
    "        Normalizes the data using pre-computed statistics.\n",
    "\n",
    "        Args:\n",
    "            data (np.array or dask.array): Data to normalize.\n",
    "            data_type (str): \"input\" or \"output\", to use appropriate statistics.\n",
    "\n",
    "        Returns:\n",
    "            Normalized data.\n",
    "        \n",
    "        Raises:\n",
    "            ValueError: If statistics for the specified data_type are not set.\n",
    "        \"\"\"\n",
    "        if data_type == \"input\":\n",
    "            if self.mean_in is None or self.std_in is None:\n",
    "                raise ValueError(\"Input statistics not set in Normalizer.\")\n",
    "            # Add a small epsilon to std to prevent division by zero if std is very small or zero\n",
    "            return (data - self.mean_in) / (self.std_in + 1e-8) \n",
    "        elif data_type == \"output\":\n",
    "            if self.mean_out is None or self.std_out is None:\n",
    "                raise ValueError(\"Output statistics not set in Normalizer.\")\n",
    "            return (data - self.mean_out) / (self.std_out + 1e-8)\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid data_type '{data_type}'. Must be 'input' or 'output'.\")\n",
    "\n",
    "    def inverse_transform_output(self, data):\n",
    "        \"\"\"\n",
    "        Applies inverse normalization to output data (predictions).\n",
    "\n",
    "        Args:\n",
    "            data (torch.Tensor or np.array): Normalized output data.\n",
    "\n",
    "        Returns:\n",
    "            Data in original physical units.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If output statistics are not set.\n",
    "        \"\"\"\n",
    "        if self.mean_out is None or self.std_out is None:\n",
    "            raise ValueError(\"Output statistics not set in Normalizer for inverse transform.\")\n",
    "        return data * (self.std_out + 1e-8) + self.mean_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e8e1fce-c1b0-43cb-9204-de384f73f2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: U-Net Model Architecture\n",
    "# (DoubleConv, Down, Up, OutConv, UNet classes)\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels_x1, in_channels_x2, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "        # in_channels_x1: channels of the feature map from the upsampling path (lower layer in decoder)\n",
    "        # in_channels_x2: channels of the feature map from the skip connection (encoder)\n",
    "        # out_channels: channels produced by this Up block\n",
    "\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            # After upsampling x1, its channel count (in_channels_x1) remains the same.\n",
    "            # It's then concatenated with x2 (in_channels_x2).\n",
    "            # So, the input to DoubleConv is (in_channels_x1 + in_channels_x2).\n",
    "            self.conv = DoubleConv(in_channels_x1 + in_channels_x2, out_channels)\n",
    "        else:\n",
    "            # ConvTranspose2d halves the channels of x1 (in_channels_x1 -> in_channels_x1 // 2)\n",
    "            self.up = nn.ConvTranspose2d(in_channels_x1, in_channels_x1 // 2, kernel_size=2, stride=2)\n",
    "            # Input to DoubleConv is (in_channels_x1 // 2 + in_channels_x2)\n",
    "            self.conv = DoubleConv(in_channels_x1 // 2 + in_channels_x2, out_channels)\n",
    "\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        # x1: feature map from upsampling path (e.g., from x_bottleneck or previous Up layer)\n",
    "        # x2: feature map from skip connection (encoder path, e.g., x4_skip)\n",
    "        x1 = self.up(x1)\n",
    "        \n",
    "        # Pad x1 to match x2's spatial dimensions if they differ\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        \n",
    "        x = torch.cat([x2, x1], dim=1) # Concatenate along channel dimension\n",
    "        return self.conv(x)\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_input_channels, n_output_channels, bilinear=True, init_features=64):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_input_channels = n_input_channels\n",
    "        self.n_output_channels = n_output_channels\n",
    "        self.bilinear = bilinear\n",
    "        self.init_features = init_features \n",
    "        \n",
    "        f = init_features # Short alias\n",
    "\n",
    "        # Encoder\n",
    "        self.inc = DoubleConv(n_input_channels, f)\n",
    "        self.down1 = Down(f, f * 2)\n",
    "        self.down2 = Down(f * 2, f * 4)\n",
    "        self.down3 = Down(f * 4, f * 8)\n",
    "        self.down4 = Down(f * 8, f * 16) # Bottleneck input features\n",
    "\n",
    "        # Decoder\n",
    "        # Arguments for Up: (channels_from_lower_upsampled_layer, channels_from_skip_connection, output_channels_for_this_Up_block)\n",
    "        self.up1 = Up(f * 16, f * 8,  f * 8, bilinear)\n",
    "        self.up2 = Up(f * 8,  f * 4,  f * 4, bilinear)\n",
    "        self.up3 = Up(f * 4,  f * 2,  f * 2, bilinear)\n",
    "        self.up4 = Up(f * 2,  f,      f,     bilinear)\n",
    "        \n",
    "        self.outc = OutConv(f, n_output_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1_skip = self.inc(x)           # -> f\n",
    "        x2_skip = self.down1(x1_skip)   # -> f * 2\n",
    "        x3_skip = self.down2(x2_skip)   # -> f * 4\n",
    "        x4_skip = self.down3(x3_skip)   # -> f * 8\n",
    "        x_bottleneck = self.down4(x4_skip) # -> f * 16\n",
    "\n",
    "        # Decoder\n",
    "        x = self.up1(x_bottleneck, x4_skip) # x_bottleneck (f*16), x4_skip (f*8). Up outputs f*8\n",
    "        x = self.up2(x, x3_skip)            # x (f*8), x3_skip (f*4). Up outputs f*4\n",
    "        x = self.up3(x, x2_skip)            # x (f*4), x2_skip (f*2). Up outputs f*2\n",
    "        x = self.up4(x, x1_skip)            # x (f*2), x1_skip (f). Up outputs f\n",
    "        \n",
    "        logits = self.outc(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b7d3515-bfac-483c-af65-198f6dc952ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: ClimateDataset and ClimateDataModule\n",
    "\n",
    "class ClimateDataset(Dataset):\n",
    "    def __init__(self, inputs_dask, outputs_dask, output_is_normalized=True):\n",
    "        \"\"\"\n",
    "        PyTorch Dataset for climate data.\n",
    "\n",
    "        Args:\n",
    "            inputs_dask (dask.array): Dask array of input features.\n",
    "            outputs_dask (dask.array): Dask array of output targets.\n",
    "            output_is_normalized (bool): Flag indicating if outputs_dask is already normalized.\n",
    "                                         Used for the test set where targets are not pre-normalized.\n",
    "        \"\"\"\n",
    "        self.size = inputs_dask.shape[0]\n",
    "        print(f\"Creating dataset with {self.size} samples...\")\n",
    "\n",
    "        inputs_np = inputs_dask.compute()\n",
    "        outputs_np = outputs_dask.compute()\n",
    "\n",
    "        self.inputs = torch.from_numpy(inputs_np).float()\n",
    "        self.outputs = torch.from_numpy(outputs_np).float()\n",
    "\n",
    "        if torch.isnan(self.inputs).any():\n",
    "            raise ValueError(\"NaNs found in input dataset after converting to tensor.\")\n",
    "        if torch.isnan(self.outputs).any():\n",
    "            raise ValueError(\"NaNs found in output dataset after converting to tensor.\")\n",
    "        \n",
    "        print(f\"Dataset created. Input shape: {self.inputs.shape}, Output shape: {self.outputs.shape}\")\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.outputs[idx]\n",
    "\n",
    "\n",
    "class ClimateDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        path,\n",
    "        input_vars,\n",
    "        output_vars,\n",
    "        train_ssps,\n",
    "        test_ssp,\n",
    "        target_member_id,\n",
    "        test_months=120,\n",
    "        batch_size=32,\n",
    "        num_workers=0,\n",
    "        seed=42, \n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters() \n",
    "        self.normalizer = Normalizer()\n",
    "\n",
    "    def prepare_data(self):\n",
    "        if not os.path.exists(self.hparams.path):\n",
    "            raise FileNotFoundError(f\"Data path not found: {self.hparams.path}. Please check config['data']['path'].\")\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        ds = xr.open_zarr(self.hparams.path, consolidated=False, chunks={\"time\": 24})\n",
    "        \n",
    "        # --- FIX for spatial_template ---\n",
    "        # The 'rsdt' variable might not have 'member_id'. Handle this conditionally.\n",
    "        rsdt_var_for_template = ds[\"rsdt\"]\n",
    "        if \"member_id\" in rsdt_var_for_template.dims:\n",
    "            spatial_template = rsdt_var_for_template.isel(time=0, ssp=0, member_id=0, drop=True)\n",
    "        else:\n",
    "            # If 'member_id' is not present, select without it.\n",
    "            # This assumes 'rsdt' is consistent across members or doesn't have that dimension.\n",
    "            spatial_template = rsdt_var_for_template.isel(time=0, ssp=0, drop=True)\n",
    "        # --- END FIX ---\n",
    "\n",
    "        def load_ssp(ssp_name):\n",
    "            input_dask_list, output_dask_list = [], []\n",
    "            \n",
    "            for var_name in self.hparams.input_vars:\n",
    "                da_var = ds[var_name].sel(ssp=ssp_name)\n",
    "                if \"latitude\" in da_var.dims: \n",
    "                    da_var = da_var.rename({\"latitude\": \"y\", \"longitude\": \"x\"})\n",
    "                # For input variables, if member_id exists, select the target_member_id.\n",
    "                # If it doesn't exist (e.g. for some forcing data), this sel will be a no-op if strict=False,\n",
    "                # or we can check existence. Xarray's sel is usually robust if the dim doesn't exist.\n",
    "                # However, to be safe, let's check.\n",
    "                if \"member_id\" in da_var.dims:\n",
    "                    da_var = da_var.sel(member_id=self.hparams.target_member_id)\n",
    "                \n",
    "                if set(da_var.dims) == {\"time\"}: \n",
    "                    da_var = da_var.broadcast_like(spatial_template).transpose(\"time\", \"y\", \"x\")\n",
    "                input_dask_list.append(da_var.data)\n",
    "            \n",
    "            for var_name in self.hparams.output_vars:\n",
    "                # Output variables are always selected by target_member_id\n",
    "                da_out = ds[var_name].sel(ssp=ssp_name, member_id=self.hparams.target_member_id)\n",
    "                if \"latitude\" in da_out.dims: \n",
    "                    da_out = da_out.rename({\"latitude\": \"y\", \"longitude\": \"x\"})\n",
    "                output_dask_list.append(da_out.data)\n",
    "\n",
    "            return da.stack(input_dask_list, axis=1), da.stack(output_dask_list, axis=1)\n",
    "\n",
    "        train_input_list, train_output_list = [], []\n",
    "        val_input_ssp370, val_output_ssp370 = None, None\n",
    "\n",
    "        for ssp in self.hparams.train_ssps:\n",
    "            x_ssp, y_ssp = load_ssp(ssp)\n",
    "            if ssp == \"ssp370\": \n",
    "                val_input_ssp370 = x_ssp[-self.hparams.test_months:]\n",
    "                val_output_ssp370 = y_ssp[-self.hparams.test_months:]\n",
    "                train_input_list.append(x_ssp[:-self.hparams.test_months])\n",
    "                train_output_list.append(y_ssp[:-self.hparams.test_months])\n",
    "            else:\n",
    "                train_input_list.append(x_ssp)\n",
    "                train_output_list.append(y_ssp)\n",
    "        \n",
    "        train_input_all_ssp = da.concatenate(train_input_list, axis=0)\n",
    "        train_output_all_ssp = da.concatenate(train_output_list, axis=0)\n",
    "\n",
    "        input_mean = da.nanmean(train_input_all_ssp, axis=(0, 2, 3), keepdims=True).compute()\n",
    "        input_std = da.nanstd(train_input_all_ssp, axis=(0, 2, 3), keepdims=True).compute()\n",
    "        self.normalizer.set_input_statistics(mean=input_mean, std=input_std)\n",
    "\n",
    "        output_mean = da.nanmean(train_output_all_ssp, axis=(0, 2, 3), keepdims=True).compute()\n",
    "        output_std = da.nanstd(train_output_all_ssp, axis=(0, 2, 3), keepdims=True).compute()\n",
    "        self.normalizer.set_output_statistics(mean=output_mean, std=output_std)\n",
    "\n",
    "        train_input_norm = self.normalizer.normalize(train_input_all_ssp, \"input\")\n",
    "        train_output_norm = self.normalizer.normalize(train_output_all_ssp, \"output\")\n",
    "        \n",
    "        val_input_norm = self.normalizer.normalize(val_input_ssp370, \"input\")\n",
    "        val_output_norm = self.normalizer.normalize(val_output_ssp370, \"output\")\n",
    "\n",
    "        test_input_ssp, test_output_ssp = load_ssp(self.hparams.test_ssp)\n",
    "        test_input_ssp = test_input_ssp[-self.hparams.test_months:] \n",
    "        test_output_ssp = test_output_ssp[-self.hparams.test_months:]\n",
    "        test_input_norm = self.normalizer.normalize(test_input_ssp, \"input\")\n",
    "\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            self.train_dataset = ClimateDataset(train_input_norm, train_output_norm)\n",
    "            self.val_dataset = ClimateDataset(val_input_norm, val_output_norm)\n",
    "        if stage == \"test\" or stage is None:\n",
    "            self.test_dataset = ClimateDataset(test_input_norm, test_output_ssp, output_is_normalized=False)\n",
    "        \n",
    "        self.lat = spatial_template.y.values\n",
    "        self.lon = spatial_template.x.values\n",
    "        self.area_weights = xr.DataArray(get_lat_weights(self.lat), dims=[\"y\"], coords={\"y\": self.lat})\n",
    "\n",
    "        ds.close()\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.hparams.batch_size, shuffle=True,\n",
    "                          num_workers=self.hparams.num_workers, pin_memory=torch.cuda.is_available(), persistent_workers=self.hparams.num_workers > 0)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.hparams.batch_size, shuffle=False,\n",
    "                          num_workers=self.hparams.num_workers, pin_memory=torch.cuda.is_available(), persistent_workers=self.hparams.num_workers > 0)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.hparams.batch_size, shuffle=False,\n",
    "                          num_workers=self.hparams.num_workers, pin_memory=torch.cuda.is_available(), persistent_workers=self.hparams.num_workers > 0)\n",
    "\n",
    "    def get_lat_weights(self):\n",
    "        return self.area_weights\n",
    "\n",
    "    def get_coords(self):\n",
    "        return self.lat, self.lon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e752dae9-03d3-4295-9c6f-408b1e2e4c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: ClimateEmulationModule (PyTorch Lightning)\n",
    "\n",
    "class ClimateEmulationModule(pl.LightningModule):\n",
    "    def __init__(self, model, learning_rate=1e-4):\n",
    "        super().__init__()\n",
    "        self.model = model \n",
    "        self.save_hyperparameters(ignore=['model']) \n",
    "        \n",
    "        self.criterion = nn.MSELoss() \n",
    "        self.normalizer = None \n",
    "        \n",
    "        self.val_preds, self.val_targets = [], []\n",
    "        self.test_preds, self.test_targets = [], []\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def _get_normalizer_from_datamodule(self):\n",
    "        \"\"\"Helper to safely get normalizer from datamodule.\"\"\"\n",
    "        if hasattr(self.trainer, 'datamodule') and self.trainer.datamodule is not None and hasattr(self.trainer.datamodule, 'normalizer'):\n",
    "            return self.trainer.datamodule.normalizer\n",
    "        else:\n",
    "            # Fallback if trainer.datamodule is not set up (e.g. direct call to test without fit)\n",
    "            # This requires 'config' to be globally accessible or passed differently.\n",
    "            print(\"Warning: Normalizer not found via self.trainer.datamodule. Attempting fallback initialization.\")\n",
    "            temp_dm = ClimateDataModule(**config[\"data\"]) \n",
    "            temp_dm.prepare_data()\n",
    "            temp_dm.setup(stage=\"test\") # Or appropriate stage to ensure normalizer stats are computed\n",
    "            return temp_dm.normalizer\n",
    "\n",
    "\n",
    "    def on_fit_start(self):\n",
    "        \"\"\"Called at the beginning of training.\"\"\"\n",
    "        self.normalizer = self._get_normalizer_from_datamodule()\n",
    "\n",
    "    def on_test_start(self):\n",
    "        \"\"\"Called at the beginning of testing.\"\"\"\n",
    "        if self.normalizer is None: # Ensure normalizer is available\n",
    "            self.normalizer = self._get_normalizer_from_datamodule()\n",
    "\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y_norm = batch \n",
    "        y_hat_norm = self(x)   \n",
    "        loss = self.criterion(y_hat_norm, y_norm)\n",
    "        self.log(\"train/loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y_norm = batch\n",
    "        y_hat_norm = self(x)\n",
    "        loss = self.criterion(y_hat_norm, y_norm)\n",
    "        self.log(\"val/loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        if self.normalizer is None: self.normalizer = self._get_normalizer_from_datamodule()\n",
    "\n",
    "        y_hat_denorm = self.normalizer.inverse_transform_output(y_hat_norm.detach().cpu().numpy())\n",
    "        y_denorm = self.normalizer.inverse_transform_output(y_norm.detach().cpu().numpy())\n",
    "        \n",
    "        self.val_preds.append(y_hat_denorm)\n",
    "        self.val_targets.append(y_denorm)\n",
    "        return loss \n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        if not self.trainer.sanity_checking: # Skip during sanity check\n",
    "            if not self.val_preds or not self.val_targets: \n",
    "                return\n",
    "\n",
    "            preds_epoch = np.concatenate(self.val_preds, axis=0)\n",
    "            trues_epoch = np.concatenate(self.val_targets, axis=0)\n",
    "            \n",
    "            if self.normalizer is None: self.normalizer = self._get_normalizer_from_datamodule()\n",
    "            \n",
    "            self._evaluate(preds_epoch, trues_epoch, phase=\"val\")\n",
    "            \n",
    "            np.save(\"val_preds.npy\", preds_epoch)\n",
    "            np.save(\"val_trues.npy\", trues_epoch)\n",
    "            \n",
    "            self.val_preds.clear() \n",
    "            self.val_targets.clear()\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y_true_denorm = batch \n",
    "        y_hat_norm = self(x)    \n",
    "\n",
    "        if self.normalizer is None: self.normalizer = self._get_normalizer_from_datamodule()\n",
    "        \n",
    "        y_hat_denorm = self.normalizer.inverse_transform_output(y_hat_norm.detach().cpu().numpy())\n",
    "        \n",
    "        self.test_preds.append(y_hat_denorm)\n",
    "        self.test_targets.append(y_true_denorm.detach().cpu().numpy()) \n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        if not self.test_preds or not self.test_targets: \n",
    "            return\n",
    "\n",
    "        preds_epoch = np.concatenate(self.test_preds, axis=0)\n",
    "        trues_epoch = np.concatenate(self.test_targets, axis=0)\n",
    "\n",
    "        if self.normalizer is None: self.normalizer = self._get_normalizer_from_datamodule()\n",
    "\n",
    "        self._evaluate(preds_epoch, trues_epoch, phase=\"test\")\n",
    "        self._save_submission(preds_epoch) \n",
    "        \n",
    "        self.test_preds.clear()\n",
    "        self.test_targets.clear()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    def _evaluate(self, preds_np, trues_np, phase=\"val\"):\n",
    "        \"\"\"Calculates and logs evaluation metrics.\"\"\"\n",
    "        # This check is important for when _evaluate might be called outside trainer.fit/test context\n",
    "        # or if datamodule is not correctly propagated.\n",
    "        if self.trainer.datamodule is None or not hasattr(self.trainer.datamodule, 'get_lat_weights'):\n",
    "            print(\"Warning: self.trainer.datamodule not fully available in _evaluate. Using fallback for coords/weights.\")\n",
    "            dm_eval = ClimateDataModule(**config[\"data\"]) # Re-init for coords, assumes global config\n",
    "            dm_eval.prepare_data()\n",
    "            dm_eval.setup(stage=phase) # Setup for the correct stage\n",
    "            area_weights = dm_eval.get_lat_weights()\n",
    "            lat, lon = dm_eval.get_coords()\n",
    "            output_vars = dm_eval.hparams.output_vars\n",
    "        else:\n",
    "            area_weights = self.trainer.datamodule.get_lat_weights()\n",
    "            lat, lon = self.trainer.datamodule.get_coords()\n",
    "            output_vars = self.trainer.datamodule.hparams.output_vars\n",
    "\n",
    "\n",
    "        time_coords = np.arange(preds_np.shape[0])\n",
    "        metrics_summary = {}\n",
    "\n",
    "        for i, var_name in enumerate(output_vars):\n",
    "            p_var = preds_np[:, i] \n",
    "            t_var = trues_np[:, i] \n",
    "            \n",
    "            p_xr = xr.DataArray(p_var, dims=[\"time\", \"y\", \"x\"], coords={\"time\": time_coords, \"y\": lat, \"x\": lon})\n",
    "            t_xr = xr.DataArray(t_var, dims=[\"time\", \"y\", \"x\"], coords={\"time\": time_coords, \"y\": lat, \"x\": lon})\n",
    "\n",
    "            rmse = np.sqrt(((p_xr - t_xr) ** 2).weighted(area_weights).mean()).item()\n",
    "            mean_rmse = np.sqrt(((p_xr.mean(\"time\") - t_xr.mean(\"time\")) ** 2).weighted(area_weights).mean()).item()\n",
    "            std_mae = np.abs(p_xr.std(\"time\") - t_xr.std(\"time\")).weighted(area_weights).mean().item()\n",
    "\n",
    "            print(f\"[{phase.upper()}] {var_name}: RMSE={rmse:.4f}, Time-Mean RMSE={mean_rmse:.4f}, Time-Stddev MAE={std_mae:.4f}\")\n",
    "            \n",
    "            metrics_summary[f\"{phase}/{var_name}/rmse\"] = rmse\n",
    "            metrics_summary[f\"{phase}/{var_name}/time_mean_rmse\"] = mean_rmse\n",
    "            metrics_summary[f\"{phase}/{var_name}/time_std_mae\"] = std_mae\n",
    "        \n",
    "        self.log_dict(metrics_summary, logger=True)\n",
    "\n",
    "    def _save_submission(self, predictions_np):\n",
    "        \"\"\"Saves model predictions to a CSV file in Kaggle submission format.\"\"\"\n",
    "        if self.trainer.datamodule is None or not hasattr(self.trainer.datamodule, 'get_coords'):\n",
    "            print(\"Warning: self.trainer.datamodule not fully available in _save_submission. Using fallback.\")\n",
    "            dm_submission = ClimateDataModule(**config[\"data\"])\n",
    "            dm_submission.prepare_data()\n",
    "            dm_submission.setup(stage=\"test\") # Ensure coords are loaded\n",
    "            lat, lon = dm_submission.get_coords()\n",
    "            output_vars = dm_submission.hparams.output_vars\n",
    "        else:\n",
    "            lat, lon = self.trainer.datamodule.get_coords()\n",
    "            output_vars = self.trainer.datamodule.hparams.output_vars\n",
    "            \n",
    "        time_coords_submission = np.arange(predictions_np.shape[0])\n",
    "\n",
    "        rows = []\n",
    "        for t_idx, t_val in enumerate(time_coords_submission):\n",
    "            for var_idx, var_name in enumerate(output_vars):\n",
    "                for y_idx, y_val in enumerate(lat):\n",
    "                    for x_idx, x_val in enumerate(lon):\n",
    "                        row_id = f\"t{t_idx:03d}_{var_name}_{y_val:.2f}_{x_val:.2f}\"\n",
    "                        pred_value = predictions_np[t_idx, var_idx, y_idx, x_idx]\n",
    "                        rows.append({\"ID\": row_id, \"Prediction\": pred_value})\n",
    "\n",
    "        submission_df = pd.DataFrame(rows)\n",
    "        submission_dir = \"submissions\"\n",
    "        os.makedirs(submission_dir, exist_ok=True)\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        filepath = os.path.join(submission_dir, f\"kaggle_submission_unet_{timestamp}.csv\")\n",
    "        submission_df.to_csv(filepath, index=False)\n",
    "        print(f\"✅ Submission saved to: {filepath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0de72c4-c536-470a-8a26-e4a73a666f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Training and Evaluation Script\n",
    "\n",
    "# --- Instantiate DataModule ---\n",
    "datamodule = ClimateDataModule(**config[\"data\"])\n",
    "# datamodule.prepare_data() # Called by Trainer when .fit() or .test() is called\n",
    "# datamodule.setup()      # Called by Trainer when .fit() or .test() is called\n",
    "\n",
    "# --- Instantiate U-Net Model ---\n",
    "n_inputs = len(config[\"data\"][\"input_vars\"])\n",
    "n_outputs = len(config[\"data\"][\"output_vars\"])\n",
    "\n",
    "unet_config_params = config.get(\"model_unet\", {}) \n",
    "init_features = unet_config_params.get(\"init_features\", 64)\n",
    "bilinear_upsampling = unet_config_params.get(\"bilinear\", True)\n",
    "\n",
    "unet_model = UNet(n_input_channels=n_inputs, \n",
    "                  n_output_channels=n_outputs, \n",
    "                  init_features=init_features,\n",
    "                  bilinear=bilinear_upsampling)\n",
    "\n",
    "# --- Instantiate Lightning Module ---\n",
    "learning_rate = config[\"training\"][\"lr\"]\n",
    "lightning_module = ClimateEmulationModule(unet_model, learning_rate=learning_rate)\n",
    "\n",
    "# --- Setup Trainer ---\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val/loss\", \n",
    "    mode=\"min\",         \n",
    "    filename=\"unet-best-{epoch:02d}-{val/loss:.2f}\", \n",
    "    save_top_k=1,       \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val/loss\",\n",
    "    patience=5, \n",
    "    verbose=True,\n",
    "    mode=\"min\"\n",
    ")\n",
    "\n",
    "trainer_params = {**config[\"trainer\"]} \n",
    "trainer_params[\"callbacks\"] = [checkpoint_callback, early_stop_callback]\n",
    "# Optional: Add logger\n",
    "# from lightning.pytorch.loggers import TensorBoardLogger\n",
    "# logger = TensorBoardLogger(\"tb_logs\", name=\"unet_climate_emulation\")\n",
    "# trainer_params[\"logger\"] = logger\n",
    "\n",
    "trainer = pl.Trainer(**trainer_params)\n",
    "\n",
    "# # --- Train the Model ---\n",
    "# print(\"Starting U-Net model training...\")\n",
    "# trainer.fit(lightning_module, datamodule=datamodule)\n",
    "# print(\"Training finished.\")\n",
    "\n",
    "# # --- Test the Model ---\n",
    "# print(\"Starting U-Net model testing using the best checkpoint...\")\n",
    "# # trainer.test will use the checkpoint_callback's best_model_path by default if available\n",
    "# # or you can specify ckpt_path=\"best\"\n",
    "# test_results = trainer.test(lightning_module, datamodule=datamodule, ckpt_path=\"best\") \n",
    "# print(\"Testing finished.\")\n",
    "# print(\"Test Results:\", test_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39ea3c62-3eb2-4a17-bacb-d49850478666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cell 9: Plotting Utilities (Optional)\n",
    "# # Ensure matplotlib, numpy, and xarray are imported (usually in Cell 1)\n",
    "\n",
    "# def plot_comparison(true_xr, pred_xr, title, cmap='viridis', diff_cmap='RdBu_r', metric_val=None, metric_name=\"Metric\"):\n",
    "#     \"\"\"\n",
    "#     Plots a comparison between ground truth, prediction, and their difference.\n",
    "#     Includes calculation and display of a spatial mean metric (e.g., RMSE).\n",
    "#     \"\"\"\n",
    "#     fig, axs = plt.subplots(1, 3, figsize=(18, 5)) \n",
    "#     fig.suptitle(title, fontsize=16) \n",
    "\n",
    "#     common_min = min(true_xr.min().item(), pred_xr.min().item())\n",
    "#     common_max = max(true_xr.max().item(), pred_xr.max().item())\n",
    "\n",
    "#     true_xr.plot(ax=axs[0], cmap=cmap, vmin=common_min, vmax=common_max, add_colorbar=True, cbar_kwargs={'label': true_xr.name or 'Value'})\n",
    "#     axs[0].set_title(f\"Ground Truth\")\n",
    "\n",
    "#     pred_xr.plot(ax=axs[1], cmap=cmap, vmin=common_min, vmax=common_max, add_colorbar=True, cbar_kwargs={'label': pred_xr.name or 'Value'})\n",
    "#     axs[1].set_title(f\"Prediction\")\n",
    "\n",
    "#     diff = pred_xr - true_xr\n",
    "#     abs_max_diff = np.max(np.abs(diff.data)) if diff.size > 0 else 0.1 \n",
    "    \n",
    "#     diff_plot_params = {'cmap': diff_cmap, 'add_colorbar': True, 'cbar_kwargs': {'label': 'Difference'}}\n",
    "#     if abs_max_diff > 0: \n",
    "#         diff_plot_params['vmin'] = -abs_max_diff\n",
    "#         diff_plot_params['vmax'] = abs_max_diff\n",
    "        \n",
    "#     diff.plot(ax=axs[2], **diff_plot_params)\n",
    "    \n",
    "#     title_suffix = \"\"\n",
    "#     if metric_val is not None:\n",
    "#         title_suffix = f\" ({metric_name}: {metric_val:.4f})\"\n",
    "#     axs[2].set_title(f\"Difference (Pred - Truth){title_suffix}\")\n",
    "\n",
    "#     plt.tight_layout(rect=[0, 0, 1, 0.96]) \n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08db76cd-147a-45aa-9b40-bfe686da30e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Cell 10: Visualization Script (Optional)\n",
    "\n",
    "# try:\n",
    "#     val_preds_loaded = np.load(\"val_preds.npy\")\n",
    "#     val_trues_loaded = np.load(\"val_trues.npy\")\n",
    "\n",
    "#     if not hasattr(datamodule, 'lat') or datamodule.lat is None:\n",
    "#         print(\"Datamodule not fully set up for visualization. Setting it up...\")\n",
    "#         # datamodule.prepare_data() # Should have been called by trainer\n",
    "#         datamodule.setup(stage=\"fit\") # Ensure lat, lon, etc. are available\n",
    "\n",
    "#     lat, lon = datamodule.get_coords()\n",
    "#     output_vars = config[\"data\"][\"output_vars\"] \n",
    "#     area_weights_vis = datamodule.get_lat_weights() \n",
    "    \n",
    "#     time_val_coords = np.arange(val_preds_loaded.shape[0])\n",
    "\n",
    "#     print(f\"\\n--- Visualizing Validation Predictions for U-Net ---\")\n",
    "#     for i, var_name in enumerate(output_vars):\n",
    "#         pred_xr = xr.DataArray(val_preds_loaded[:, i], dims=[\"time\", \"y\", \"x\"], \n",
    "#                                coords={\"time\": time_val_coords, \"y\": lat, \"x\": lon}, name=var_name)\n",
    "#         true_xr = xr.DataArray(val_trues_loaded[:, i], dims=[\"time\", \"y\", \"x\"], \n",
    "#                                coords={\"time\": time_val_coords, \"y\": lat, \"x\": lon}, name=var_name)\n",
    "\n",
    "#         pred_mean = pred_xr.mean(\"time\")\n",
    "#         true_mean = true_xr.mean(\"time\")\n",
    "#         mean_rmse_var = np.sqrt(((pred_mean - true_mean) ** 2).weighted(area_weights_vis).mean()).item()\n",
    "#         plot_comparison(true_mean, pred_mean, \n",
    "#                         f\"U-Net: {var_name.upper()} - Validation Time-Mean\",\n",
    "#                         metric_val=mean_rmse_var, metric_name=\"Time-Mean RMSE\")\n",
    "\n",
    "#         pred_std = pred_xr.std(\"time\")\n",
    "#         true_std = true_xr.std(\"time\")\n",
    "#         std_mae_var = np.abs(pred_std - true_std).weighted(area_weights_vis).mean().item()\n",
    "#         plot_comparison(true_std, pred_std, \n",
    "#                         f\"U-Net: {var_name.upper()} - Validation Time-StdDev\", cmap=\"plasma\",\n",
    "#                         metric_val=std_mae_var, metric_name=\"Time-StdDev MAE\")\n",
    "\n",
    "#         if len(time_val_coords) > 0:\n",
    "#             t_idx_random = np.random.randint(0, len(time_val_coords))\n",
    "#             pred_sample = pred_xr.isel(time=t_idx_random)\n",
    "#             true_sample = true_xr.isel(time=t_idx_random)\n",
    "#             sample_rmse_var = np.sqrt(((pred_sample - true_sample) ** 2).weighted(area_weights_vis).mean()).item()\n",
    "#             plot_comparison(true_sample, pred_sample, \n",
    "#                             f\"U-Net: {var_name.upper()} - Validation Sample (Timestep {t_idx_random})\",\n",
    "#                             metric_val=sample_rmse_var, metric_name=\"RMSE\")\n",
    "#         else:\n",
    "#             print(f\"No time steps available in validation predictions for {var_name} to plot a random sample.\")\n",
    "\n",
    "# except FileNotFoundError:\n",
    "#     print(\"val_preds.npy or val_trues.npy not found. \"\n",
    "#           \"Ensure that the training and validation loop (trainer.fit) has been run successfully, \"\n",
    "#           \"and the on_validation_epoch_end method in ClimateEmulationModule saved these files.\")\n",
    "# except AttributeError as e:\n",
    "#     print(f\"AttributeError during visualization: {e}. Ensure datamodule is correctly initialized and set up.\")\n",
    "#     print(\"This might happen if 'datamodule' from the training cell is not in scope or wasn't fully set up.\")\n",
    "# except Exception as e:\n",
    "#     print(f\"An error occurred during visualization: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fb2292f-7977-48aa-912d-f590f2b11109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fine-Tuning Run 1/11 ---\n",
      "Parameters: {'unet_init_features': 32, 'lr': 0.0001, 'optimizer_type': 'AdamW', 'scheduler_type': 'CosineAnnealingLR', 'batch_size': 32, 'max_epochs_ft': 20}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model for run 1 with params: {'unet_init_features': 32, 'lr': 0.0001, 'optimizer_type': 'AdamW', 'scheduler_type': 'CosineAnnealingLR', 'batch_size': 32, 'max_epochs_ft': 20}\n",
      "Creating dataset with 2703 samples...\n",
      "Dataset created. Input shape: torch.Size([2703, 5, 48, 72]), Output shape: torch.Size([2703, 2, 48, 72])\n",
      "Creating dataset with 360 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type    | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | model     | UNet    | 7.9 M  | train\n",
      "1 | criterion | MSELoss | 0      | train\n",
      "----------------------------------------------\n",
      "7.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.9 M     Total params\n",
      "31.401    Total estimated model params size (MB)\n",
      "96        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created. Input shape: torch.Size([360, 5, 48, 72]), Output shape: torch.Size([360, 2, 48, 72])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e39f707841d046b0a4352fb630d7762f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=6.3136, Time-Mean RMSE=4.8641, Time-Stddev MAE=1.6958\n",
      "[VAL] pr: RMSE=2.8983, Time-Mean RMSE=1.1522, Time-Stddev MAE=1.6099\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=4.8153, Time-Mean RMSE=3.2095, Time-Stddev MAE=1.1445\n",
      "[VAL] pr: RMSE=2.6841, Time-Mean RMSE=0.8863, Time-Stddev MAE=1.3645\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=3.8066, Time-Mean RMSE=2.7326, Time-Stddev MAE=0.9541\n",
      "[VAL] pr: RMSE=2.4140, Time-Mean RMSE=0.7449, Time-Stddev MAE=1.1659\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=3.1148, Time-Mean RMSE=1.9308, Time-Stddev MAE=0.7901\n",
      "[VAL] pr: RMSE=2.3256, Time-Mean RMSE=0.6328, Time-Stddev MAE=1.0233\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=2.8506, Time-Mean RMSE=1.7266, Time-Stddev MAE=0.7011\n",
      "[VAL] pr: RMSE=2.2382, Time-Mean RMSE=0.6019, Time-Stddev MAE=0.8468\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=2.6291, Time-Mean RMSE=1.6324, Time-Stddev MAE=0.6565\n",
      "[VAL] pr: RMSE=2.1203, Time-Mean RMSE=0.5392, Time-Stddev MAE=0.8495\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=2.4801, Time-Mean RMSE=1.5376, Time-Stddev MAE=0.6083\n",
      "[VAL] pr: RMSE=2.1160, Time-Mean RMSE=0.5443, Time-Stddev MAE=0.9160\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=2.5046, Time-Mean RMSE=1.5660, Time-Stddev MAE=0.5711\n",
      "[VAL] pr: RMSE=2.1241, Time-Mean RMSE=0.5000, Time-Stddev MAE=0.8379\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=2.4789, Time-Mean RMSE=1.3203, Time-Stddev MAE=0.6064\n",
      "[VAL] pr: RMSE=2.1529, Time-Mean RMSE=0.4955, Time-Stddev MAE=0.8584\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=2.2729, Time-Mean RMSE=1.3327, Time-Stddev MAE=0.5677\n",
      "[VAL] pr: RMSE=2.0773, Time-Mean RMSE=0.4738, Time-Stddev MAE=0.8068\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=2.2438, Time-Mean RMSE=1.3015, Time-Stddev MAE=0.5563\n",
      "[VAL] pr: RMSE=2.0671, Time-Mean RMSE=0.4502, Time-Stddev MAE=0.8474\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=2.2877, Time-Mean RMSE=1.2881, Time-Stddev MAE=0.5278\n",
      "[VAL] pr: RMSE=2.0856, Time-Mean RMSE=0.4728, Time-Stddev MAE=0.8490\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=2.2204, Time-Mean RMSE=1.2438, Time-Stddev MAE=0.5436\n",
      "[VAL] pr: RMSE=2.0807, Time-Mean RMSE=0.4590, Time-Stddev MAE=0.8541\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=2.1734, Time-Mean RMSE=1.2142, Time-Stddev MAE=0.5333\n",
      "[VAL] pr: RMSE=2.0558, Time-Mean RMSE=0.4388, Time-Stddev MAE=0.8303\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=2.1551, Time-Mean RMSE=1.1987, Time-Stddev MAE=0.5101\n",
      "[VAL] pr: RMSE=2.0582, Time-Mean RMSE=0.4420, Time-Stddev MAE=0.8277\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=2.1361, Time-Mean RMSE=1.1745, Time-Stddev MAE=0.5173\n",
      "[VAL] pr: RMSE=2.0502, Time-Mean RMSE=0.4171, Time-Stddev MAE=0.8274\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=2.1116, Time-Mean RMSE=1.1567, Time-Stddev MAE=0.5073\n",
      "[VAL] pr: RMSE=2.0466, Time-Mean RMSE=0.4230, Time-Stddev MAE=0.8029\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=2.1185, Time-Mean RMSE=1.1686, Time-Stddev MAE=0.4939\n",
      "[VAL] pr: RMSE=2.0478, Time-Mean RMSE=0.4211, Time-Stddev MAE=0.8258\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=2.0737, Time-Mean RMSE=1.1592, Time-Stddev MAE=0.4876\n",
      "[VAL] pr: RMSE=2.0324, Time-Mean RMSE=0.4089, Time-Stddev MAE=0.8104\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=2.1229, Time-Mean RMSE=1.1734, Time-Stddev MAE=0.5044\n",
      "[VAL] pr: RMSE=2.0435, Time-Mean RMSE=0.4139, Time-Stddev MAE=0.8151\n",
      "Evaluating model from run 1 on validation set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /home/ruz039/private/cse151b/DL_for_Climate_Emulation/lightning_logs/ft_unet_run_1/checkpoints/best-unet-epoch=18-val/loss=0.170.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/ruz039/private/cse151b/DL_for_Climate_Emulation/lightning_logs/ft_unet_run_1/checkpoints/best-unet-epoch=18-val/loss=0.170.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa960198b8664221a20cf0c12d6c8ac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=2.0737, Time-Mean RMSE=1.1592, Time-Stddev MAE=0.4876\n",
      "[VAL] pr: RMSE=2.0324, Time-Mean RMSE=0.4089, Time-Stddev MAE=0.8104\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        val/loss            0.17025740444660187\n",
      "       val/pr/rmse          2.0323846340179443\n",
      "  val/pr/time_mean_rmse     0.4089001715183258\n",
      "   val/pr/time_std_mae      0.8104011416435242\n",
      "      val/tas/rmse          2.0737040042877197\n",
      " val/tas/time_mean_rmse     1.1592297554016113\n",
      "  val/tas/time_std_mae      0.4876391291618347\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Run 1 Validation Loss: 0.1703\n",
      "\n",
      "--- Fine-Tuning Run 2/11 ---\n",
      "Parameters: {'unet_init_features': 128, 'lr': 0.0001, 'optimizer_type': 'AdamW', 'scheduler_type': 'StepLR', 'batch_size': 32, 'max_epochs_ft': 20}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model for run 2 with params: {'unet_init_features': 128, 'lr': 0.0001, 'optimizer_type': 'AdamW', 'scheduler_type': 'StepLR', 'batch_size': 32, 'max_epochs_ft': 20}\n",
      "Creating dataset with 2703 samples...\n",
      "Dataset created. Input shape: torch.Size([2703, 5, 48, 72]), Output shape: torch.Size([2703, 2, 48, 72])\n",
      "Creating dataset with 360 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created. Input shape: torch.Size([360, 5, 48, 72]), Output shape: torch.Size([360, 2, 48, 72])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type    | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | model     | UNet    | 125 M  | train\n",
      "1 | criterion | MSELoss | 0      | train\n",
      "----------------------------------------------\n",
      "125 M     Trainable params\n",
      "0         Non-trainable params\n",
      "125 M     Total params\n",
      "502.059   Total estimated model params size (MB)\n",
      "96        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e3408dbcabb42d9abb7218a7843340e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91625bdcabad43b88bf118d0e3a61d1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=5.2094, Time-Mean RMSE=3.7463, Time-Stddev MAE=1.2224\n",
      "[VAL] pr: RMSE=2.7432, Time-Mean RMSE=0.8626, Time-Stddev MAE=1.5619\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "881a5d50842f4edf8362ca55e391a007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=3.2537, Time-Mean RMSE=1.9809, Time-Stddev MAE=0.9290\n",
      "[VAL] pr: RMSE=2.3885, Time-Mean RMSE=0.7687, Time-Stddev MAE=1.1608\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fd1ff38a9c140cca74f5e9f299d017c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=2.9165, Time-Mean RMSE=1.8312, Time-Stddev MAE=0.8352\n",
      "[VAL] pr: RMSE=2.1631, Time-Mean RMSE=0.6031, Time-Stddev MAE=0.9031\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d6f6691ad1d4135a40e03037bae68fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=2.2012, Time-Mean RMSE=1.3924, Time-Stddev MAE=0.5370\n",
      "[VAL] pr: RMSE=2.0777, Time-Mean RMSE=0.5831, Time-Stddev MAE=0.8052\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "068ae4201d4b4bbc8eb32201c8d145f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=2.0698, Time-Mean RMSE=1.2886, Time-Stddev MAE=0.5041\n",
      "[VAL] pr: RMSE=2.0480, Time-Mean RMSE=0.5123, Time-Stddev MAE=0.8150\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a8bebe95cc44cb083ddf297364bfa9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=2.2661, Time-Mean RMSE=1.5868, Time-Stddev MAE=0.4636\n",
      "[VAL] pr: RMSE=2.0397, Time-Mean RMSE=0.4809, Time-Stddev MAE=0.8414\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a98a18cbf79f4cc3844581cff71f1f36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=2.2115, Time-Mean RMSE=1.5222, Time-Stddev MAE=0.5168\n",
      "[VAL] pr: RMSE=2.0741, Time-Mean RMSE=0.5343, Time-Stddev MAE=0.8088\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c79c319636bc46cfaf65ca64dce0daff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=2.0471, Time-Mean RMSE=1.3239, Time-Stddev MAE=0.5105\n",
      "[VAL] pr: RMSE=2.0313, Time-Mean RMSE=0.4758, Time-Stddev MAE=0.8267\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b4bc0b8266f46a4aea34f7e99fc3bb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.7457, Time-Mean RMSE=0.9119, Time-Stddev MAE=0.3843\n",
      "[VAL] pr: RMSE=1.9907, Time-Mean RMSE=0.3733, Time-Stddev MAE=0.7521\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b42ea113b8db477ab1076137ea086b0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.8037, Time-Mean RMSE=1.0523, Time-Stddev MAE=0.4274\n",
      "[VAL] pr: RMSE=2.0016, Time-Mean RMSE=0.4186, Time-Stddev MAE=0.7758\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2b69effacf947b2b74054d47608489f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.8387, Time-Mean RMSE=1.0859, Time-Stddev MAE=0.4428\n",
      "[VAL] pr: RMSE=1.9865, Time-Mean RMSE=0.3833, Time-Stddev MAE=0.7358\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eac515d847254c5f95b7ec58c68962e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.6943, Time-Mean RMSE=0.8980, Time-Stddev MAE=0.3924\n",
      "[VAL] pr: RMSE=2.0007, Time-Mean RMSE=0.4369, Time-Stddev MAE=0.7555\n",
      "Evaluating model from run 2 on validation set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /home/ruz039/private/cse151b/DL_for_Climate_Emulation/lightning_logs/ft_unet_run_2/checkpoints/best-unet-epoch=08-val/loss=0.161.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/ruz039/private/cse151b/DL_for_Climate_Emulation/lightning_logs/ft_unet_run_2/checkpoints/best-unet-epoch=08-val/loss=0.161.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0935802fdcf40c2b6f98e9a5e839f9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.7457, Time-Mean RMSE=0.9119, Time-Stddev MAE=0.3843\n",
      "[VAL] pr: RMSE=1.9907, Time-Mean RMSE=0.3733, Time-Stddev MAE=0.7521\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        val/loss            0.16142010688781738\n",
      "       val/pr/rmse           1.990682601928711\n",
      "  val/pr/time_mean_rmse     0.3733293414115906\n",
      "   val/pr/time_std_mae      0.7521287798881531\n",
      "      val/tas/rmse          1.7456622123718262\n",
      " val/tas/time_mean_rmse      0.911907434463501\n",
      "  val/tas/time_std_mae      0.38432568311691284\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 2 Validation Loss: 0.1614\n",
      "\n",
      "--- Fine-Tuning Run 3/11 ---\n",
      "Parameters: {'unet_init_features': 32, 'lr': 0.001, 'optimizer_type': 'Adam', 'scheduler_type': 'CosineAnnealingLR', 'batch_size': 32, 'max_epochs_ft': 20}\n",
      "Fitting model for run 3 with params: {'unet_init_features': 32, 'lr': 0.001, 'optimizer_type': 'Adam', 'scheduler_type': 'CosineAnnealingLR', 'batch_size': 32, 'max_epochs_ft': 20}\n",
      "Creating dataset with 2703 samples...\n",
      "Dataset created. Input shape: torch.Size([2703, 5, 48, 72]), Output shape: torch.Size([2703, 2, 48, 72])\n",
      "Creating dataset with 360 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type    | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | model     | UNet    | 7.9 M  | train\n",
      "1 | criterion | MSELoss | 0      | train\n",
      "----------------------------------------------\n",
      "7.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.9 M     Total params\n",
      "31.401    Total estimated model params size (MB)\n",
      "96        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created. Input shape: torch.Size([360, 5, 48, 72]), Output shape: torch.Size([360, 2, 48, 72])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "924efe356e14428d8e796a3088a6163c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b45d06c407a496e95f6f1f45e5b2815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=4.4118, Time-Mean RMSE=2.7856, Time-Stddev MAE=1.4107\n",
      "[VAL] pr: RMSE=2.7762, Time-Mean RMSE=0.9568, Time-Stddev MAE=1.5287\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f459634fb60409795f83f3d7d64e9d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=3.8275, Time-Mean RMSE=2.8249, Time-Stddev MAE=1.1180\n",
      "[VAL] pr: RMSE=2.5182, Time-Mean RMSE=1.0303, Time-Stddev MAE=1.0598\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e5272e737e746319f9b803b761582e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=2.6856, Time-Mean RMSE=1.8764, Time-Stddev MAE=0.7557\n",
      "[VAL] pr: RMSE=2.2337, Time-Mean RMSE=0.7645, Time-Stddev MAE=0.8388\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59997fa5f18549e4b568713c6e160a16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=2.3852, Time-Mean RMSE=1.6536, Time-Stddev MAE=0.6358\n",
      "[VAL] pr: RMSE=2.0996, Time-Mean RMSE=0.5976, Time-Stddev MAE=0.8060\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcc197c8fa3e4910904de6a698d43031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=2.4516, Time-Mean RMSE=1.6640, Time-Stddev MAE=0.6460\n",
      "[VAL] pr: RMSE=2.1259, Time-Mean RMSE=0.6085, Time-Stddev MAE=0.8332\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "893fdb3941674448a433f8e80b8de708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=2.1873, Time-Mean RMSE=1.4732, Time-Stddev MAE=0.5840\n",
      "[VAL] pr: RMSE=2.0542, Time-Mean RMSE=0.4995, Time-Stddev MAE=0.7998\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d915ed9f0b064c41bc4538aac2434572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=2.1139, Time-Mean RMSE=1.4122, Time-Stddev MAE=0.5294\n",
      "[VAL] pr: RMSE=2.0751, Time-Mean RMSE=0.5808, Time-Stddev MAE=0.8006\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c0c1580b18c402dbd4d799a5cf9167b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=2.0692, Time-Mean RMSE=1.3672, Time-Stddev MAE=0.5404\n",
      "[VAL] pr: RMSE=2.0413, Time-Mean RMSE=0.5132, Time-Stddev MAE=0.7840\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5167d060bf384d3ca5880f662ea93c4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.9657, Time-Mean RMSE=1.2290, Time-Stddev MAE=0.4867\n",
      "[VAL] pr: RMSE=2.0211, Time-Mean RMSE=0.4669, Time-Stddev MAE=0.7402\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "929d091fd9ff49658a1e50b3133b6646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.9109, Time-Mean RMSE=1.1875, Time-Stddev MAE=0.4600\n",
      "[VAL] pr: RMSE=2.0094, Time-Mean RMSE=0.4316, Time-Stddev MAE=0.7726\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ced9f0588234033ae41bd9270bca875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.9786, Time-Mean RMSE=1.2560, Time-Stddev MAE=0.4993\n",
      "[VAL] pr: RMSE=2.0314, Time-Mean RMSE=0.4880, Time-Stddev MAE=0.7706\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc5259862f994310a54fd97e86121b69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.8528, Time-Mean RMSE=1.1237, Time-Stddev MAE=0.4485\n",
      "[VAL] pr: RMSE=1.9957, Time-Mean RMSE=0.3896, Time-Stddev MAE=0.7308\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0e41007fbac44569df937c0175174f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.8240, Time-Mean RMSE=1.1053, Time-Stddev MAE=0.4238\n",
      "[VAL] pr: RMSE=1.9812, Time-Mean RMSE=0.3663, Time-Stddev MAE=0.7559\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27d6a86bf827464f8add7d0a4cb45c83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.8249, Time-Mean RMSE=1.1094, Time-Stddev MAE=0.3973\n",
      "[VAL] pr: RMSE=1.9959, Time-Mean RMSE=0.4091, Time-Stddev MAE=0.7439\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecd5a8c32884452aae23a89690307592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.7819, Time-Mean RMSE=1.0602, Time-Stddev MAE=0.3890\n",
      "[VAL] pr: RMSE=1.9752, Time-Mean RMSE=0.3428, Time-Stddev MAE=0.7472\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cda06f21eb7474a8f4ad31f6c4689f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.7793, Time-Mean RMSE=1.0531, Time-Stddev MAE=0.3960\n",
      "[VAL] pr: RMSE=1.9828, Time-Mean RMSE=0.3748, Time-Stddev MAE=0.7603\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65a9506182ed420ead143da29f951594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.7193, Time-Mean RMSE=0.9899, Time-Stddev MAE=0.3851\n",
      "[VAL] pr: RMSE=1.9698, Time-Mean RMSE=0.3470, Time-Stddev MAE=0.7629\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5285fb555eb24ef3b39fd948e4852011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.7226, Time-Mean RMSE=0.9821, Time-Stddev MAE=0.3720\n",
      "[VAL] pr: RMSE=1.9693, Time-Mean RMSE=0.3399, Time-Stddev MAE=0.7453\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa7f968f51664804a10eac9e29a33b88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.7206, Time-Mean RMSE=0.9953, Time-Stddev MAE=0.3673\n",
      "[VAL] pr: RMSE=1.9638, Time-Mean RMSE=0.3261, Time-Stddev MAE=0.7559\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ed65ee59b5a4906aa72cc25792d0540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.7206, Time-Mean RMSE=0.9930, Time-Stddev MAE=0.3697\n",
      "[VAL] pr: RMSE=1.9630, Time-Mean RMSE=0.3227, Time-Stddev MAE=0.7485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model from run 3 on validation set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /home/ruz039/private/cse151b/DL_for_Climate_Emulation/lightning_logs/ft_unet_run_3/checkpoints/best-unet-epoch=19-val/loss=0.157.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/ruz039/private/cse151b/DL_for_Climate_Emulation/lightning_logs/ft_unet_run_3/checkpoints/best-unet-epoch=19-val/loss=0.157.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b8f619d94fa4a4ca8dc91c15a5490b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.7206, Time-Mean RMSE=0.9930, Time-Stddev MAE=0.3697\n",
      "[VAL] pr: RMSE=1.9630, Time-Mean RMSE=0.3227, Time-Stddev MAE=0.7485\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        val/loss            0.15701662003993988\n",
      "       val/pr/rmse          1.9630497694015503\n",
      "  val/pr/time_mean_rmse     0.32268384099006653\n",
      "   val/pr/time_std_mae       0.748530387878418\n",
      "      val/tas/rmse          1.7206227779388428\n",
      " val/tas/time_mean_rmse     0.9930409789085388\n",
      "  val/tas/time_std_mae      0.3696863055229187\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Run 3 Validation Loss: 0.1570\n",
      "\n",
      "--- Fine-Tuning Run 4/11 ---\n",
      "Parameters: {'unet_init_features': 64, 'lr': 0.0005, 'optimizer_type': 'Adam', 'scheduler_type': 'StepLR', 'batch_size': 16, 'max_epochs_ft': 20}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model for run 4 with params: {'unet_init_features': 64, 'lr': 0.0005, 'optimizer_type': 'Adam', 'scheduler_type': 'StepLR', 'batch_size': 16, 'max_epochs_ft': 20}\n",
      "Creating dataset with 2703 samples...\n",
      "Dataset created. Input shape: torch.Size([2703, 5, 48, 72]), Output shape: torch.Size([2703, 2, 48, 72])\n",
      "Creating dataset with 360 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type    | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | model     | UNet    | 31.4 M | train\n",
      "1 | criterion | MSELoss | 0      | train\n",
      "----------------------------------------------\n",
      "31.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "31.4 M    Total params\n",
      "125.544   Total estimated model params size (MB)\n",
      "96        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created. Input shape: torch.Size([360, 5, 48, 72]), Output shape: torch.Size([360, 2, 48, 72])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bcedc817f8e4e378d65b117df9214d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9981581f53df4a80a87a4779607a51f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=4.0178, Time-Mean RMSE=2.4745, Time-Stddev MAE=1.1351\n",
      "[VAL] pr: RMSE=2.7169, Time-Mean RMSE=0.8944, Time-Stddev MAE=1.5494\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39e9bf5f951845f6b6f60fec4401f602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=3.7058, Time-Mean RMSE=2.2512, Time-Stddev MAE=1.5496\n",
      "[VAL] pr: RMSE=2.4221, Time-Mean RMSE=0.9656, Time-Stddev MAE=1.1389\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57f09f6411544fd5b33617bf5157830e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=2.2521, Time-Mean RMSE=1.4402, Time-Stddev MAE=0.5554\n",
      "[VAL] pr: RMSE=2.1207, Time-Mean RMSE=0.5698, Time-Stddev MAE=0.8596\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8f087d2535041feb81ca020824d396c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=2.1615, Time-Mean RMSE=1.3547, Time-Stddev MAE=0.5437\n",
      "[VAL] pr: RMSE=2.1026, Time-Mean RMSE=0.6106, Time-Stddev MAE=0.8403\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b3c2ded8b0b46a28c43c19931f59d7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=2.0050, Time-Mean RMSE=1.2896, Time-Stddev MAE=0.4955\n",
      "[VAL] pr: RMSE=2.0421, Time-Mean RMSE=0.4866, Time-Stddev MAE=0.8378\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c021be500e643cbb600f43340406620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.9077, Time-Mean RMSE=1.1355, Time-Stddev MAE=0.4668\n",
      "[VAL] pr: RMSE=2.0328, Time-Mean RMSE=0.4873, Time-Stddev MAE=0.8052\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf88717466344328f2d2c0ae5d1333f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=2.2074, Time-Mean RMSE=1.4563, Time-Stddev MAE=0.6229\n",
      "[VAL] pr: RMSE=2.0871, Time-Mean RMSE=0.5825, Time-Stddev MAE=0.8820\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0169d4efbe7844298205af967d572211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.7871, Time-Mean RMSE=1.0294, Time-Stddev MAE=0.3932\n",
      "[VAL] pr: RMSE=1.9972, Time-Mean RMSE=0.4105, Time-Stddev MAE=0.7811\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d648c5fb5f2411c92c5d10f20e4968e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.8052, Time-Mean RMSE=1.0993, Time-Stddev MAE=0.4175\n",
      "[VAL] pr: RMSE=2.0421, Time-Mean RMSE=0.5560, Time-Stddev MAE=0.8047\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9120d6f3b0954d1dbaba01501bd8611f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.7744, Time-Mean RMSE=1.0581, Time-Stddev MAE=0.4013\n",
      "[VAL] pr: RMSE=2.0562, Time-Mean RMSE=0.5648, Time-Stddev MAE=0.8048\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a81feaeea4d849c0bc20081294c94dd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.8645, Time-Mean RMSE=1.1786, Time-Stddev MAE=0.3935\n",
      "[VAL] pr: RMSE=1.9866, Time-Mean RMSE=0.3879, Time-Stddev MAE=0.7411\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4304d1ffd4041fd94ab6de5bf36dcde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.6912, Time-Mean RMSE=0.9216, Time-Stddev MAE=0.3657\n",
      "[VAL] pr: RMSE=1.9771, Time-Mean RMSE=0.3519, Time-Stddev MAE=0.7823\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a36480e0cde42daa03f2c31430c691e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.6686, Time-Mean RMSE=0.9317, Time-Stddev MAE=0.3799\n",
      "[VAL] pr: RMSE=1.9949, Time-Mean RMSE=0.4091, Time-Stddev MAE=0.8194\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f38ac6706489406693b7c6a1b2b8dcbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.6860, Time-Mean RMSE=0.9505, Time-Stddev MAE=0.3908\n",
      "[VAL] pr: RMSE=2.0142, Time-Mean RMSE=0.4759, Time-Stddev MAE=0.7501\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7069f72a6d044598a020c14bab37cf20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.6520, Time-Mean RMSE=0.9145, Time-Stddev MAE=0.3565\n",
      "[VAL] pr: RMSE=1.9801, Time-Mean RMSE=0.3687, Time-Stddev MAE=0.7549\n",
      "Evaluating model from run 4 on validation set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /home/ruz039/private/cse151b/DL_for_Climate_Emulation/lightning_logs/ft_unet_run_4/checkpoints/best-unet-epoch=11-val/loss=0.159.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/ruz039/private/cse151b/DL_for_Climate_Emulation/lightning_logs/ft_unet_run_4/checkpoints/best-unet-epoch=11-val/loss=0.159.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdc05f9d4ab24867b6fb8415939d7de5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.6912, Time-Mean RMSE=0.9216, Time-Stddev MAE=0.3657\n",
      "[VAL] pr: RMSE=1.9771, Time-Mean RMSE=0.3519, Time-Stddev MAE=0.7823\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        val/loss            0.15948902070522308\n",
      "       val/pr/rmse          1.9770545959472656\n",
      "  val/pr/time_mean_rmse     0.35193729400634766\n",
      "   val/pr/time_std_mae       0.782333254814148\n",
      "      val/tas/rmse          1.6911522150039673\n",
      " val/tas/time_mean_rmse     0.9215661287307739\n",
      "  val/tas/time_std_mae      0.3656538128852844\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Run 4 Validation Loss: 0.1595\n",
      "\n",
      "--- Fine-Tuning Run 5/11 ---\n",
      "Parameters: {'unet_init_features': 128, 'lr': 0.0005, 'optimizer_type': 'AdamW', 'scheduler_type': None, 'batch_size': 64, 'max_epochs_ft': 20}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model for run 5 with params: {'unet_init_features': 128, 'lr': 0.0005, 'optimizer_type': 'AdamW', 'scheduler_type': None, 'batch_size': 64, 'max_epochs_ft': 20}\n",
      "Creating dataset with 2703 samples...\n",
      "Dataset created. Input shape: torch.Size([2703, 5, 48, 72]), Output shape: torch.Size([2703, 2, 48, 72])\n",
      "Creating dataset with 360 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type    | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | model     | UNet    | 125 M  | train\n",
      "1 | criterion | MSELoss | 0      | train\n",
      "----------------------------------------------\n",
      "125 M     Trainable params\n",
      "0         Non-trainable params\n",
      "125 M     Total params\n",
      "502.059   Total estimated model params size (MB)\n",
      "96        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created. Input shape: torch.Size([360, 5, 48, 72]), Output shape: torch.Size([360, 2, 48, 72])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruz039/.local/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (43) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1cd549a9c06447593ff985d7ee07791",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "195bbcf90f1f4ceb89962cf8b39b1dc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=4.7638, Time-Mean RMSE=3.1174, Time-Stddev MAE=1.5548\n",
      "[VAL] pr: RMSE=3.0080, Time-Mean RMSE=1.3159, Time-Stddev MAE=1.7295\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "004e7992ca594ec88561d05a6d13ac0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=4.4820, Time-Mean RMSE=2.9405, Time-Stddev MAE=1.2795\n",
      "[VAL] pr: RMSE=3.0581, Time-Mean RMSE=1.5464, Time-Stddev MAE=1.6282\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e55963f41be4a1b8bbf925691a636b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=4.1962, Time-Mean RMSE=2.4267, Time-Stddev MAE=1.0823\n",
      "[VAL] pr: RMSE=2.8195, Time-Mean RMSE=1.0269, Time-Stddev MAE=1.5137\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 122] Disk quota exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.11/shutil.py:853\u001b[0m, in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 853\u001b[0m     os\u001b[38;5;241m.\u001b[39mrename(src, real_dst)\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 18] Invalid cross-device link: '/tmp/tmp0wgt__1k' -> '/home/ruz039/private/cse151b/DL_for_Climate_Emulation/lightning_logs/ft_unet_run_5/checkpoints/best-unet-epoch=02-val/loss=0.337.ckpt'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 128\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# 6. Run training\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting model for run \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with params: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 128\u001b[0m \u001b[43mtrainer_ft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlightning_module_ft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatamodule_ft\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# 7. Evaluate on the validation set using the best checkpoint from this run\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating model from run \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m on validation set...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:561\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 561\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:48\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     51\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:599\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    592\u001b[0m     download_model_from_registry(ckpt_path, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    593\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    595\u001b[0m     ckpt_path,\n\u001b[1;32m    596\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    597\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    598\u001b[0m )\n\u001b[0;32m--> 599\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    602\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:1012\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m-> 1012\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1017\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:1056\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1054\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_sanity_check()\n\u001b[1;32m   1055\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1056\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1057\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:217\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance()\n\u001b[0;32m--> 217\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_advance_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:470\u001b[0m, in \u001b[0;36m_FitLoop.on_advance_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    468\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(trainer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_train_epoch_end\u001b[39m\u001b[38;5;124m\"\u001b[39m, monitoring_callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    469\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_lightning_module_hook(trainer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_train_epoch_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 470\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_callback_hooks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mon_train_epoch_end\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonitoring_callbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    472\u001b[0m trainer\u001b[38;5;241m.\u001b[39m_logger_connector\u001b[38;5;241m.\u001b[39mon_epoch_end()\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrestarting \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch_loop\u001b[38;5;241m.\u001b[39m_num_ready_batches_reached():\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;66;03m# since metric-based schedulers require access to metrics and those are not currently saved in the\u001b[39;00m\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;66;03m# checkpoint, the plateau schedulers shouldn't be updated\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:227\u001b[0m, in \u001b[0;36m_call_callback_hooks\u001b[0;34m(trainer, hook_name, monitoring_callbacks, *args, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(fn):\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Callback]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcallback\u001b[38;5;241m.\u001b[39mstate_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 227\u001b[0m             \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pl_module:\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    231\u001b[0m     pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:325\u001b[0m, in \u001b[0;36mModelCheckpoint.on_train_epoch_end\u001b[0;34m(self, trainer, pl_module)\u001b[0m\n\u001b[1;32m    323\u001b[0m monitor_candidates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_monitor_candidates(trainer)\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_every_n_epochs \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (trainer\u001b[38;5;241m.\u001b[39mcurrent_epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_every_n_epochs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 325\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_topk_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonitor_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_last_checkpoint(trainer, monitor_candidates)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:385\u001b[0m, in \u001b[0;36mModelCheckpoint._save_topk_checkpoint\u001b[0;34m(self, trainer, monitor_candidates)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(m)\n\u001b[1;32m    384\u001b[0m         warning_cache\u001b[38;5;241m.\u001b[39mwarn(m)\n\u001b[0;32m--> 385\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_monitor_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonitor_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_none_monitor_checkpoint(trainer, monitor_candidates)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:705\u001b[0m, in \u001b[0;36mModelCheckpoint._save_monitor_checkpoint\u001b[0;34m(self, trainer, monitor_candidates)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_monitor_top_k(trainer, current):\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m current \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 705\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_best_and_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonitor_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[1;32m    707\u001b[0m     epoch \u001b[38;5;241m=\u001b[39m monitor_candidates[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:757\u001b[0m, in \u001b[0;36mModelCheckpoint._update_best_and_save\u001b[0;34m(self, current, trainer, monitor_candidates)\u001b[0m\n\u001b[1;32m    752\u001b[0m     step \u001b[38;5;241m=\u001b[39m monitor_candidates[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    753\u001b[0m     rank_zero_info(\n\u001b[1;32m    754\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124md\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, global step \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124md\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmonitor\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m reached \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m0.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    755\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (best \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_model_score\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m0.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m), saving model to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m as top \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    756\u001b[0m     )\n\u001b[0;32m--> 757\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m del_filepath \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_remove_checkpoint(trainer, del_filepath, filepath):\n\u001b[1;32m    760\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_remove_checkpoint(trainer, del_filepath)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:390\u001b[0m, in \u001b[0;36mModelCheckpoint._save_checkpoint\u001b[0;34m(self, trainer, filepath)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_save_checkpoint\u001b[39m(\u001b[38;5;28mself\u001b[39m, trainer: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.Trainer\u001b[39m\u001b[38;5;124m\"\u001b[39m, filepath: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 390\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_weights_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_global_step_saved \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mglobal_step\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_checkpoint_saved \u001b[38;5;241m=\u001b[39m filepath\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:1397\u001b[0m, in \u001b[0;36mTrainer.save_checkpoint\u001b[0;34m(self, filepath, weights_only, storage_options)\u001b[0m\n\u001b[1;32m   1395\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msave_checkpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1396\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39mdump_checkpoint(weights_only)\n\u001b[0;32m-> 1397\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1398\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mbarrier(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrainer.save_checkpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py:491\u001b[0m, in \u001b[0;36mStrategy.save_checkpoint\u001b[0;34m(self, checkpoint, filepath, storage_options)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Save model/training states as a checkpoint file through state-dump and file-write.\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \n\u001b[1;32m    484\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    488\u001b[0m \n\u001b[1;32m    489\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_global_zero:\n\u001b[0;32m--> 491\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpoint_io\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/lightning/fabric/plugins/io/torch_io.py:58\u001b[0m, in \u001b[0;36mTorchCheckpointIO.save_checkpoint\u001b[0;34m(self, checkpoint, path, storage_options)\u001b[0m\n\u001b[1;32m     56\u001b[0m fs \u001b[38;5;241m=\u001b[39m get_filesystem(path)\n\u001b[1;32m     57\u001b[0m fs\u001b[38;5;241m.\u001b[39mmakedirs(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(path), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 58\u001b[0m \u001b[43m_atomic_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/lightning/fabric/utilities/cloud_io.py:89\u001b[0m, in \u001b[0;36m_atomic_save\u001b[0;34m(checkpoint, filepath)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# We use a transaction here to avoid file corruption if the save gets interrupted\u001b[39;00m\n\u001b[1;32m     88\u001b[0m fs, urlpath \u001b[38;5;241m=\u001b[39m fsspec\u001b[38;5;241m.\u001b[39mcore\u001b[38;5;241m.\u001b[39murl_to_fs(\u001b[38;5;28mstr\u001b[39m(filepath))\n\u001b[0;32m---> 89\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransaction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murlpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbytesbuffer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetvalue\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/fsspec/transaction.py:28\u001b[0m, in \u001b[0;36mTransaction.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"End transaction and commit, if exit is not due to exception\"\"\"\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# only commit if there was no exception\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomplete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexc_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfs:\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfs\u001b[38;5;241m.\u001b[39m_intrans \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/fsspec/transaction.py:44\u001b[0m, in \u001b[0;36mTransaction.complete\u001b[0;34m(self, commit)\u001b[0m\n\u001b[1;32m     42\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfiles\u001b[38;5;241m.\u001b[39mpopleft()\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m commit:\n\u001b[0;32m---> 44\u001b[0m     \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     f\u001b[38;5;241m.\u001b[39mdiscard()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/fsspec/implementations/local.py:372\u001b[0m, in \u001b[0;36mLocalFileOpener.commit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautocommit:\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only commit if not already set to autocommit\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 372\u001b[0m \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmove\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/shutil.py:873\u001b[0m, in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    871\u001b[0m         rmtree(src)\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 873\u001b[0m         \u001b[43mcopy_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_dst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    874\u001b[0m         os\u001b[38;5;241m.\u001b[39munlink(src)\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m real_dst\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/shutil.py:448\u001b[0m, in \u001b[0;36mcopy2\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(dst):\n\u001b[1;32m    447\u001b[0m     dst \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dst, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(src))\n\u001b[0;32m--> 448\u001b[0m \u001b[43mcopyfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_symlinks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    449\u001b[0m copystat(src, dst, follow_symlinks\u001b[38;5;241m=\u001b[39mfollow_symlinks)\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dst\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/shutil.py:258\u001b[0m, in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(src, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fsrc:\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 258\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfdst\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# macOS\u001b[39;49;00m\n\u001b[1;32m    260\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_HAS_FCOPYFILE\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01mtry\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 122] Disk quota exceeded"
     ]
    }
   ],
   "source": [
    "# Cell 11: U-Net Fine-Tuning Loop\n",
    "\n",
    "from copy import deepcopy\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor, TQDMProgressBar\n",
    "\n",
    "# hyperparameter_sets = [\n",
    "#     {\"unet_init_features\": 32, \"lr\": 1e-4, \"optimizer_type\": \"AdamW\", \"scheduler_type\": \"CosineAnnealingLR\", \"batch_size\": 32, \"max_epochs_ft\": 5},\n",
    "#     {\"unet_init_features\": 64, \"lr\": 1e-4, \"optimizer_type\": \"AdamW\", \"scheduler_type\": \"CosineAnnealingLR\", \"batch_size\": 32, \"max_epochs_ft\": 5},\n",
    "#     {\"unet_init_features\": 32, \"lr\": 5e-4, \"optimizer_type\": \"Adam\",  \"scheduler_type\": None,              \"batch_size\": 64, \"max_epochs_ft\": 5},\n",
    "#     {\"unet_init_features\": 64, \"lr\": 1e-3, \"optimizer_type\": \"AdamW\", \"scheduler_type\": \"CosineAnnealingLR\", \"batch_size\": 64, \"max_epochs_ft\": 8},\n",
    "# ]\n",
    "\n",
    "# best: {\"unet_init_features\": 32, \"lr\": 1e-4, \"optimizer_type\": \"AdamW\", \"scheduler_type\": \"CosineAnnealingLR\", \"batch_size\": 32, \"max_epochs_ft\": 5}\n",
    "\n",
    "hyperparameter_sets = [\n",
    "    # original four (gets 1)\n",
    "    {\"unet_init_features\": 32,  \"lr\": 1e-4, \"optimizer_type\": \"AdamW\",   \"scheduler_type\": \"CosineAnnealingLR\", \"batch_size\": 32, \"max_epochs_ft\": 20},\n",
    "    {\"unet_init_features\": 128, \"lr\": 1e-4, \"optimizer_type\": \"AdamW\",   \"scheduler_type\": \"StepLR\",             \"batch_size\": 32, \"max_epochs_ft\": 20},\n",
    "    {\"unet_init_features\": 32,  \"lr\": 1e-3, \"optimizer_type\": \"Adam\",    \"scheduler_type\": \"CosineAnnealingLR\", \"batch_size\": 32, \"max_epochs_ft\": 20},\n",
    "    {\"unet_init_features\": 64,  \"lr\": 5e-4, \"optimizer_type\": \"Adam\",    \"scheduler_type\": \"StepLR\",             \"batch_size\": 16, \"max_epochs_ft\": 20},\n",
    "    {\"unet_init_features\": 128, \"lr\": 5e-4, \"optimizer_type\": \"AdamW\",   \"scheduler_type\": None,                \"batch_size\": 64, \"max_epochs_ft\": 20},\n",
    "    {\"unet_init_features\": 32,  \"lr\": 2e-4, \"optimizer_type\": \"AdamW\",   \"scheduler_type\": \"CosineAnnealingLR\", \"batch_size\": 16, \"max_epochs_ft\": 20},\n",
    "    {\"unet_init_features\": 128, \"lr\": 1e-3, \"optimizer_type\": \"Adam\",    \"scheduler_type\": None,                \"batch_size\": 32, \"max_epochs_ft\": 20},\n",
    "\n",
    "    # four new combos with different optimizers\n",
    "    {\"unet_init_features\": 32,  \"lr\": 1e-2, \"optimizer_type\": \"SGD\",     \"scheduler_type\": \"StepLR\",             \"batch_size\": 32, \"max_epochs_ft\": 20},\n",
    "    {\"unet_init_features\": 64,  \"lr\": 1e-2, \"optimizer_type\": \"SGD\",     \"scheduler_type\": None,                \"batch_size\": 64, \"max_epochs_ft\": 20},\n",
    "    {\"unet_init_features\": 32,  \"lr\": 5e-4, \"optimizer_type\": \"RMSprop\", \"scheduler_type\": \"CosineAnnealingLR\", \"batch_size\": 16, \"max_epochs_ft\": 20},\n",
    "    {\"unet_init_features\": 64,  \"lr\": 1e-3, \"optimizer_type\": \"Adagrad\", \"scheduler_type\": \"StepLR\",             \"batch_size\": 32, \"max_epochs_ft\": 20},\n",
    "]\n",
    "\n",
    "\n",
    "fine_tuning_results = []\n",
    "\n",
    "# Original config for data path and other fixed settings\n",
    "base_config_data_path = config[\"data\"][\"path\"] \n",
    "base_config_trainer_fixed = {k: v for k, v in config[\"trainer\"].items() if k not in [\"max_epochs\", \"callbacks\", \"logger\", \"default_root_dir\"]}\n",
    "\n",
    "\n",
    "for i, params in enumerate(hyperparameter_sets):\n",
    "    print(f\"\\n--- Fine-Tuning Run {i+1}/{len(hyperparameter_sets)} ---\")\n",
    "    print(f\"Parameters: {params}\")\n",
    "\n",
    "    # 1. Create a deep copy of the base config and update it\n",
    "    current_config = deepcopy(config) # Start with the global config\n",
    "    current_config[\"data\"][\"batch_size\"] = params[\"batch_size\"]\n",
    "    current_config[\"model_unet\"][\"init_features\"] = params[\"unet_init_features\"]\n",
    "    # We'll handle lr, optimizer, scheduler directly in LightningModule or Trainer setup\n",
    "    \n",
    "    # 2. Re-instantiate DataModule (important if batch_size changes)\n",
    "    # The datamodule setup (normalization stats) should ideally be based on the full training set once.\n",
    "    # For fine-tuning, if only batch_size changes, re-instantiating is okay.\n",
    "    # If other data aspects change (like SSPs), ensure setup() is appropriate.\n",
    "    datamodule_ft = ClimateDataModule(**current_config[\"data\"])\n",
    "    # datamodule_ft.prepare_data() # Called by Trainer\n",
    "    # datamodule_ft.setup(stage=\"fit\") # Called by Trainer\n",
    "\n",
    "    # 3. Re-instantiate U-Net model\n",
    "    n_inputs_ft = len(current_config[\"data\"][\"input_vars\"])\n",
    "    n_outputs_ft = len(current_config[\"data\"][\"output_vars\"])\n",
    "    \n",
    "    unet_model_ft = UNet(\n",
    "        n_input_channels=n_inputs_ft, \n",
    "        n_output_channels=n_outputs_ft, \n",
    "        init_features=current_config[\"model_unet\"][\"init_features\"],\n",
    "        bilinear=current_config[\"model_unet\"].get(\"bilinear\", True) # Use bilinear from config or default\n",
    "    )\n",
    "\n",
    "    # 4. Re-instantiate LightningModule\n",
    "    # We will override configure_optimizers for this run\n",
    "    lightning_module_ft = ClimateEmulationModule(\n",
    "        unet_model_ft, \n",
    "        learning_rate=params[\"lr\"] # Pass the current learning rate\n",
    "    )\n",
    "\n",
    "    # Override configure_optimizers for the current fine-tuning run\n",
    "    def custom_configure_optimizers(self_lm):\n",
    "        if params[\"optimizer_type\"] == \"AdamW\":\n",
    "            optimizer = optim.AdamW(self_lm.parameters(), lr=self_lm.hparams.learning_rate, weight_decay=0.01)\n",
    "        else: # Default to Adam\n",
    "            optimizer = optim.Adam(self_lm.parameters(), lr=self_lm.hparams.learning_rate)\n",
    "        \n",
    "        if params[\"scheduler_type\"] == \"CosineAnnealingLR\":\n",
    "            # T_max could be params[\"max_epochs_ft\"] or total training steps\n",
    "            scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=params[\"max_epochs_ft\"], eta_min=1e-6)\n",
    "            return {\"optimizer\": optimizer, \"lr_scheduler\": {\"scheduler\": scheduler, \"interval\": \"epoch\"}}\n",
    "        return optimizer\n",
    "\n",
    "    # Bind the custom method to this instance of the LightningModule\n",
    "    import types\n",
    "    lightning_module_ft.configure_optimizers = types.MethodType(custom_configure_optimizers, lightning_module_ft)\n",
    "\n",
    "\n",
    "\n",
    "    # 5. Re-instantiate Trainer\n",
    "    # Callbacks for this fine-tuning run\n",
    "    # Using a unique directory for each run's checkpoints/logs can be helpful\n",
    "    run_specific_dir = f\"ft_unet_run_{i+1}\"\n",
    "    \n",
    "    ft_checkpoint_callback = ModelCheckpoint(\n",
    "        monitor=\"val/loss\",\n",
    "        mode=\"min\",\n",
    "        dirpath=os.path.join(\"lightning_logs\", run_specific_dir, \"checkpoints\"), # Save checkpoints in run-specific dir\n",
    "        filename=\"best-unet-{epoch:02d}-{val/loss:.3f}\",\n",
    "        save_top_k=1,\n",
    "        verbose=False # Less verbose for multiple runs\n",
    "    )\n",
    "    ft_early_stop_callback = EarlyStopping(\n",
    "        monitor=\"val/loss\",\n",
    "        patience=3, # Shorter patience for fine-tuning runs\n",
    "        verbose=False,\n",
    "        mode=\"min\"\n",
    "    )\n",
    "\n",
    "    ft_progress_bar = TQDMProgressBar(refresh_rate=10)\n",
    "\n",
    "    trainer_ft_config = {\n",
    "        **base_config_trainer_fixed, # Use fixed parts of trainer config\n",
    "        \"max_epochs\": params[\"max_epochs_ft\"],\n",
    "        \"callbacks\": [ft_checkpoint_callback, ft_early_stop_callback, ft_progress_bar],\n",
    "        \"logger\": pl.loggers.TensorBoardLogger(\"tb_logs\", name=f\"unet_ft_run_{i+1}\"), # Log each run separately\n",
    "        \"default_root_dir\": os.path.join(\"lightning_logs\", run_specific_dir) # Root dir for this run\n",
    "    }\n",
    "    trainer_ft = pl.Trainer(**trainer_ft_config)\n",
    "\n",
    "    # 6. Run training\n",
    "    print(f\"Fitting model for run {i+1} with params: {params}\")\n",
    "    trainer_ft.fit(lightning_module_ft, datamodule=datamodule_ft)\n",
    "    \n",
    "    # 7. Evaluate on the validation set using the best checkpoint from this run\n",
    "    print(f\"Evaluating model from run {i+1} on validation set...\")\n",
    "    # The test method here is used for validation set evaluation for fine-tuning\n",
    "    # Ensure your ClimateEmulationModule's test_step and on_test_epoch_end\n",
    "    # are suitable for this (e.g., they log \"test/...\" metrics which you'd interpret as \"finetune_val/...\")\n",
    "    # Or, better, use trainer.validate if you only need validation metrics.\n",
    "    # For simplicity, let's assume trainer.test() is okay and we look at its output.\n",
    "    # The checkpoint_callback saves the best model based on \"val/loss\".\n",
    "    \n",
    "    val_results = trainer_ft.validate(lightning_module_ft, datamodule=datamodule_ft, ckpt_path=\"best\")\n",
    "    best_val_loss = val_results[0].get('val/loss', float('inf')) # Get the final validation loss\n",
    "\n",
    "    # You might also want to run .test() on the actual test set if you want to see\n",
    "    # how each hyperparameter set performs on the final test data, but typically\n",
    "    # hyperparameter tuning is done based on validation set performance.\n",
    "    # For now, we'll store validation results.\n",
    "    \n",
    "    current_run_results = {\n",
    "        \"params\": params,\n",
    "        \"best_val_loss\": best_val_loss,\n",
    "        \"val_metrics\": val_results[0] # Store all metrics from validation\n",
    "        # \"test_metrics_on_val_split\": test_on_val_results[0] # If you used .test on val_dataloader\n",
    "    }\n",
    "    fine_tuning_results.append(current_run_results)\n",
    "    print(f\"Run {i+1} Validation Loss: {best_val_loss:.4f}\")\n",
    "\n",
    "\n",
    "# 8. Analyze fine-tuning results\n",
    "print(\"\\n--- Fine-Tuning Complete ---\")\n",
    "best_run = None\n",
    "best_loss = float('inf')\n",
    "\n",
    "for result in fine_tuning_results:\n",
    "    print(f\"Params: {result['params']}, Best Val Loss: {result['best_val_loss']:.4f}\")\n",
    "    if result['best_val_loss'] < best_loss:\n",
    "        best_loss = result['best_val_loss']\n",
    "        best_run = result\n",
    "\n",
    "if best_run:\n",
    "    print(f\"\\nBest performing set of parameters:\")\n",
    "    print(f\"Params: {best_run['params']}\")\n",
    "    print(f\"Validation Loss: {best_run['best_val_loss']:.4f}\")\n",
    "    print(f\"Full Validation Metrics: {best_run['val_metrics']}\")\n",
    "else:\n",
    "    print(\"No fine-tuning runs completed or no results to analyze.\")\n",
    "\n",
    "# After identifying the best hyperparameters, you would typically retrain your model\n",
    "# on the full training data (including the part of ssp370 used for validation here)\n",
    "# for a larger number of epochs, and then evaluate on the final held-out test set (ssp245).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b08fda5-60ab-4820-b87a-b79c7e8b7973",
   "metadata": {},
   "source": [
    "best_params_unet: {'unet_init_features': 64,\n",
    " 'lr': 0.0001,\n",
    " 'optimizer_type': 'AdamW',\n",
    " 'scheduler_type': 'CosineAnnealingLR',\n",
    " 'batch_size': 32,\n",
    " 'max_epochs_ft': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23ea2691-663a-44a3-b4ba-0fb5976763dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unet_init_features': 64,\n",
       " 'lr': 0.0001,\n",
       " 'optimizer_type': 'AdamW',\n",
       " 'scheduler_type': 'CosineAnnealingLR',\n",
       " 'batch_size': 32,\n",
       " 'max_epochs_ft': 5}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7987d283-8ad2-468c-a30e-5f56185aba59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting U-Net Final Training with Best Hyperparameters ---\n",
      "Using best U-Net parameters: {'unet_init_features': 64, 'lr': 0.0001, 'optimizer_type': 'AdamW', 'scheduler_type': 'CosineAnnealingLR', 'batch_size': 32, 'max_epochs_ft': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting final U-Net model with best params: {'unet_init_features': 64, 'lr': 0.0001, 'optimizer_type': 'AdamW', 'scheduler_type': 'CosineAnnealingLR', 'batch_size': 32, 'max_epochs_ft': 5}\n",
      "Creating dataset with 2703 samples...\n",
      "Dataset created. Input shape: torch.Size([2703, 5, 48, 72]), Output shape: torch.Size([2703, 2, 48, 72])\n",
      "Creating dataset with 360 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type    | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | model     | UNet    | 31.4 M | train\n",
      "1 | criterion | MSELoss | 0      | train\n",
      "----------------------------------------------\n",
      "31.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "31.4 M    Total params\n",
      "125.544   Total estimated model params size (MB)\n",
      "96        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created. Input shape: torch.Size([360, 5, 48, 72]), Output shape: torch.Size([360, 2, 48, 72])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0ed18c6623e40c89dd91d921ccc741c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved. New best score: 0.354\n",
      "Epoch 0, global step 85: 'val/loss' reached 0.35412 (best 0.35412), saving model to '/home/ruz039/private/cse151b/DL_for_Climate_Emulation/lightning_logs/final_unet_run/checkpoints/final-best-unet-epoch=00-val/loss=0.354.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=4.6756, Time-Mean RMSE=2.9997, Time-Stddev MAE=1.4171\n",
      "[VAL] pr: RMSE=2.8718, Time-Mean RMSE=1.1280, Time-Stddev MAE=1.6364\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved by 0.104 >= min_delta = 0.0. New best score: 0.250\n",
      "Epoch 1, global step 170: 'val/loss' reached 0.25040 (best 0.25040), saving model to '/home/ruz039/private/cse151b/DL_for_Climate_Emulation/lightning_logs/final_unet_run/checkpoints/final-best-unet-epoch=01-val/loss=0.250.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=3.3871, Time-Mean RMSE=2.0922, Time-Stddev MAE=0.8684\n",
      "[VAL] pr: RMSE=2.4418, Time-Mean RMSE=0.7451, Time-Stddev MAE=1.1813\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved by 0.032 >= min_delta = 0.0. New best score: 0.218\n",
      "Epoch 2, global step 255: 'val/loss' reached 0.21838 (best 0.21838), saving model to '/home/ruz039/private/cse151b/DL_for_Climate_Emulation/lightning_logs/final_unet_run/checkpoints/final-best-unet-epoch=02-val/loss=0.218.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=3.1998, Time-Mean RMSE=2.1231, Time-Stddev MAE=0.8184\n",
      "[VAL] pr: RMSE=2.2566, Time-Mean RMSE=0.6638, Time-Stddev MAE=0.9735\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved by 0.039 >= min_delta = 0.0. New best score: 0.179\n",
      "Epoch 3, global step 340: 'val/loss' reached 0.17946 (best 0.17946), saving model to '/home/ruz039/private/cse151b/DL_for_Climate_Emulation/lightning_logs/final_unet_run/checkpoints/final-best-unet-epoch=03-val/loss=0.179.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=2.3045, Time-Mean RMSE=1.5245, Time-Stddev MAE=0.5885\n",
      "[VAL] pr: RMSE=2.0808, Time-Mean RMSE=0.5461, Time-Stddev MAE=0.8473\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved by 0.004 >= min_delta = 0.0. New best score: 0.175\n",
      "Epoch 4, global step 425: 'val/loss' reached 0.17514 (best 0.17514), saving model to '/home/ruz039/private/cse151b/DL_for_Climate_Emulation/lightning_logs/final_unet_run/checkpoints/final-best-unet-epoch=04-val/loss=0.175.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=2.2324, Time-Mean RMSE=1.4714, Time-Stddev MAE=0.5525\n",
      "[VAL] pr: RMSE=2.0589, Time-Mean RMSE=0.5192, Time-Stddev MAE=0.8460\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved by 0.000 >= min_delta = 0.0. New best score: 0.175\n",
      "Epoch 5, global step 510: 'val/loss' reached 0.17507 (best 0.17507), saving model to '/home/ruz039/private/cse151b/DL_for_Climate_Emulation/lightning_logs/final_unet_run/checkpoints/final-best-unet-epoch=05-val/loss=0.175.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=2.1329, Time-Mean RMSE=1.3450, Time-Stddev MAE=0.5243\n",
      "[VAL] pr: RMSE=2.0633, Time-Mean RMSE=0.5476, Time-Stddev MAE=0.8276\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved by 0.003 >= min_delta = 0.0. New best score: 0.172\n",
      "Epoch 6, global step 595: 'val/loss' reached 0.17226 (best 0.17226), saving model to '/home/ruz039/private/cse151b/DL_for_Climate_Emulation/lightning_logs/final_unet_run/checkpoints/final-best-unet-epoch=06-val/loss=0.172.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=2.1397, Time-Mean RMSE=1.3708, Time-Stddev MAE=0.5376\n",
      "[VAL] pr: RMSE=2.0468, Time-Mean RMSE=0.4955, Time-Stddev MAE=0.8550\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved by 0.005 >= min_delta = 0.0. New best score: 0.167\n",
      "Epoch 7, global step 680: 'val/loss' reached 0.16720 (best 0.16720), saving model to '/home/ruz039/private/cse151b/DL_for_Climate_Emulation/lightning_logs/final_unet_run/checkpoints/final-best-unet-epoch=07-val/loss=0.167.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.9983, Time-Mean RMSE=1.2085, Time-Stddev MAE=0.4942\n",
      "[VAL] pr: RMSE=2.0186, Time-Mean RMSE=0.4482, Time-Stddev MAE=0.8197\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved by 0.001 >= min_delta = 0.0. New best score: 0.166\n",
      "Epoch 8, global step 765: 'val/loss' reached 0.16615 (best 0.16615), saving model to '/home/ruz039/private/cse151b/DL_for_Climate_Emulation/lightning_logs/final_unet_run/checkpoints/final-best-unet-epoch=08-val/loss=0.166.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.9510, Time-Mean RMSE=1.1619, Time-Stddev MAE=0.4505\n",
      "[VAL] pr: RMSE=2.0146, Time-Mean RMSE=0.4161, Time-Stddev MAE=0.8049\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved by 0.002 >= min_delta = 0.0. New best score: 0.164\n",
      "Epoch 9, global step 850: 'val/loss' reached 0.16437 (best 0.16437), saving model to '/home/ruz039/private/cse151b/DL_for_Climate_Emulation/lightning_logs/final_unet_run/checkpoints/final-best-unet-epoch=09-val/loss=0.164.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.9372, Time-Mean RMSE=1.1764, Time-Stddev MAE=0.4260\n",
      "[VAL] pr: RMSE=2.0040, Time-Mean RMSE=0.4110, Time-Stddev MAE=0.8258\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 935: 'val/loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.8836, Time-Mean RMSE=1.0863, Time-Stddev MAE=0.4396\n",
      "[VAL] pr: RMSE=2.0131, Time-Mean RMSE=0.4628, Time-Stddev MAE=0.8137\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved by 0.002 >= min_delta = 0.0. New best score: 0.163\n",
      "Epoch 11, global step 1020: 'val/loss' reached 0.16282 (best 0.16282), saving model to '/home/ruz039/private/cse151b/DL_for_Climate_Emulation/lightning_logs/final_unet_run/checkpoints/final-best-unet-epoch=11-val/loss=0.163.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.8246, Time-Mean RMSE=1.0323, Time-Stddev MAE=0.4154\n",
      "[VAL] pr: RMSE=1.9970, Time-Mean RMSE=0.4027, Time-Stddev MAE=0.7839\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved by 0.001 >= min_delta = 0.0. New best score: 0.162\n",
      "Epoch 12, global step 1105: 'val/loss' reached 0.16156 (best 0.16156), saving model to '/home/ruz039/private/cse151b/DL_for_Climate_Emulation/lightning_logs/final_unet_run/checkpoints/final-best-unet-epoch=12-val/loss=0.162.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.8301, Time-Mean RMSE=1.0540, Time-Stddev MAE=0.4153\n",
      "[VAL] pr: RMSE=1.9882, Time-Mean RMSE=0.3885, Time-Stddev MAE=0.7937\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved by 0.000 >= min_delta = 0.0. New best score: 0.161\n",
      "Epoch 13, global step 1190: 'val/loss' reached 0.16123 (best 0.16123), saving model to '/home/ruz039/private/cse151b/DL_for_Climate_Emulation/lightning_logs/final_unet_run/checkpoints/final-best-unet-epoch=13-val/loss=0.161.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.7929, Time-Mean RMSE=1.0121, Time-Stddev MAE=0.4022\n",
      "[VAL] pr: RMSE=1.9881, Time-Mean RMSE=0.3910, Time-Stddev MAE=0.7936\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved by 0.000 >= min_delta = 0.0. New best score: 0.161\n",
      "Epoch 14, global step 1275: 'val/loss' reached 0.16096 (best 0.16096), saving model to '/home/ruz039/private/cse151b/DL_for_Climate_Emulation/lightning_logs/final_unet_run/checkpoints/final-best-unet-epoch=14-val/loss=0.161.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.7799, Time-Mean RMSE=0.9767, Time-Stddev MAE=0.4033\n",
      "[VAL] pr: RMSE=1.9862, Time-Mean RMSE=0.3856, Time-Stddev MAE=0.8032\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e78ba2feb42c498a97ff7c5319cea61c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved by 0.001 >= min_delta = 0.0. New best score: 0.160\n",
      "Epoch 15, global step 1360: 'val/loss' reached 0.16038 (best 0.16038), saving model to '/home/ruz039/private/cse151b/DL_for_Climate_Emulation/lightning_logs/final_unet_run/checkpoints/final-best-unet-epoch=15-val/loss=0.160.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.7839, Time-Mean RMSE=0.9797, Time-Stddev MAE=0.4022\n",
      "[VAL] pr: RMSE=1.9827, Time-Mean RMSE=0.3641, Time-Stddev MAE=0.8098\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fcb920c8e7049d9ac6fcb6f58b254ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved by 0.001 >= min_delta = 0.0. New best score: 0.159\n",
      "Epoch 16, global step 1445: 'val/loss' reached 0.15911 (best 0.15911), saving model to '/home/ruz039/private/cse151b/DL_for_Climate_Emulation/lightning_logs/final_unet_run/checkpoints/final-best-unet-epoch=16-val/loss=0.159.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.7470, Time-Mean RMSE=0.9589, Time-Stddev MAE=0.3870\n",
      "[VAL] pr: RMSE=1.9752, Time-Mean RMSE=0.3516, Time-Stddev MAE=0.7673\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce8d7133cfe14b1fa58c17cc5ce1dcfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17, global step 1530: 'val/loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.7566, Time-Mean RMSE=0.9641, Time-Stddev MAE=0.3989\n",
      "[VAL] pr: RMSE=1.9796, Time-Mean RMSE=0.3682, Time-Stddev MAE=0.7846\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8b04b173fb54959be1ba9ca9575d498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved by 0.000 >= min_delta = 0.0. New best score: 0.159\n",
      "Epoch 18, global step 1615: 'val/loss' reached 0.15865 (best 0.15865), saving model to '/home/ruz039/private/cse151b/DL_for_Climate_Emulation/lightning_logs/final_unet_run/checkpoints/final-best-unet-epoch=18-val/loss=0.159.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.7433, Time-Mean RMSE=0.9430, Time-Stddev MAE=0.3912\n",
      "[VAL] pr: RMSE=1.9724, Time-Mean RMSE=0.3459, Time-Stddev MAE=0.7824\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07a8cabbd9034468b600442bc0151b58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved by 0.000 >= min_delta = 0.0. New best score: 0.158\n",
      "Epoch 19, global step 1700: 'val/loss' reached 0.15841 (best 0.15841), saving model to '/home/ruz039/private/cse151b/DL_for_Climate_Emulation/lightning_logs/final_unet_run/checkpoints/final-best-unet-epoch=19-val/loss=0.158.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.7502, Time-Mean RMSE=0.9523, Time-Stddev MAE=0.3925\n",
      "[VAL] pr: RMSE=1.9702, Time-Mean RMSE=0.3376, Time-Stddev MAE=0.7781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing final U-Net model on test set (ssp245)...\n",
      "Creating dataset with 360 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /home/ruz039/private/cse151b/DL_for_Climate_Emulation/lightning_logs/final_unet_run/checkpoints/final-best-unet-epoch=19-val/loss=0.158.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created. Input shape: torch.Size([360, 5, 48, 72]), Output shape: torch.Size([360, 2, 48, 72])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/ruz039/private/cse151b/DL_for_Climate_Emulation/lightning_logs/final_unet_run/checkpoints/final-best-unet-epoch=19-val/loss=0.158.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a87dc35e13ea41c593db71554906852b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] tas: RMSE=290.5800, Time-Mean RMSE=290.5367, Time-Stddev MAE=3.7093\n",
      "[TEST] pr: RMSE=4.3301, Time-Mean RMSE=3.8674, Time-Stddev MAE=1.3886\n",
      "✅ Submission saved to: submissions/kaggle_submission_unet_20250522_193549.csv\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test/pr/rmse           4.330072402954102\n",
      " test/pr/time_mean_rmse     3.8674283027648926\n",
      "  test/pr/time_std_mae      1.3885520696640015\n",
      "      test/tas/rmse          290.5799865722656\n",
      " test/tas/time_mean_rmse     290.5366516113281\n",
      "  test/tas/time_std_mae     3.7092957496643066\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Final U-Net Test Results (on ssp245): [{'test/tas/rmse': 290.5799865722656, 'test/tas/time_mean_rmse': 290.5366516113281, 'test/tas/time_std_mae': 3.7092957496643066, 'test/pr/rmse': 4.330072402954102, 'test/pr/time_mean_rmse': 3.8674283027648926, 'test/pr/time_std_mae': 1.3885520696640015}]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5033256-ba88-4200-a144-2de9c96b63bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Visualizing Validation Predictions for Final U-Net ---\n",
      "datamodule_final_unet not fully set up for visualization. Setting it up...\n",
      "Creating dataset with 2703 samples...\n",
      "Dataset created. Input shape: torch.Size([2703, 5, 48, 72]), Output shape: torch.Size([2703, 2, 48, 72])\n",
      "Creating dataset with 360 samples...\n",
      "Dataset created. Input shape: torch.Size([360, 5, 48, 72]), Output shape: torch.Size([360, 2, 48, 72])\n",
      "NameError during U-Net final visualization: name 'plot_comparison' is not defined. Ensure 'best_run_unet' was defined and the final training cell (Cell 18) ran successfully.\n"
     ]
    }
   ],
   "source": [
    "# Cell 13: U-Net - Final Visualization\n",
    "# This cell loads the validation predictions saved during the FINAL U-Net training run and plots them.\n",
    "\n",
    "print(f\"\\n--- Visualizing Validation Predictions for Final U-Net ---\")\n",
    "try:\n",
    "    # Load the saved predictions and true values from the final U-Net run\n",
    "    val_preds_loaded_final_unet = np.load(\"val_preds.npy\") \n",
    "    val_trues_loaded_final_unet = np.load(\"val_trues.npy\")\n",
    "\n",
    "    # Ensure datamodule_final_unet is available from the training cell (Cell 18)\n",
    "    if 'datamodule_final_unet' not in globals() or not hasattr(datamodule_final_unet, 'lat') or datamodule_final_unet.lat is None:\n",
    "        print(\"datamodule_final_unet not fully set up for visualization. Setting it up...\")\n",
    "        datamodule_final_unet_viz = ClimateDataModule(**config[\"data\"]) # Use global config for safety\n",
    "        datamodule_final_unet_viz.setup(stage=\"fit\") \n",
    "        lat, lon = datamodule_final_unet_viz.get_coords()\n",
    "        output_vars = config[\"data\"][\"output_vars\"] \n",
    "        area_weights_vis = datamodule_final_unet_viz.get_lat_weights()\n",
    "    else:\n",
    "        lat, lon = datamodule_final_unet.get_coords()\n",
    "        output_vars = config[\"data\"][\"output_vars\"] \n",
    "        area_weights_vis = datamodule_final_unet.get_lat_weights() \n",
    "    \n",
    "    time_val_coords = np.arange(val_preds_loaded_final_unet.shape[0])\n",
    "\n",
    "    for i, var_name in enumerate(output_vars):\n",
    "        pred_xr_final_unet = xr.DataArray(val_preds_loaded_final_unet[:, i], dims=[\"time\", \"y\", \"x\"], \n",
    "                                   coords={\"time\": time_val_coords, \"y\": lat, \"x\": lon}, name=var_name)\n",
    "        true_xr_final_unet = xr.DataArray(val_trues_loaded_final_unet[:, i], dims=[\"time\", \"y\", \"x\"], \n",
    "                                   coords={\"time\": time_val_coords, \"y\": lat, \"x\": lon}, name=var_name)\n",
    "\n",
    "        pred_mean_final_unet = pred_xr_final_unet.mean(\"time\")\n",
    "        true_mean_final_unet = true_xr_final_unet.mean(\"time\")\n",
    "        mean_rmse_var_final_unet = np.sqrt(((pred_mean_final_unet - true_mean_final_unet) ** 2).weighted(area_weights_vis).mean()).item()\n",
    "        plot_comparison(true_mean_final_unet, pred_mean_final_unet, \n",
    "                        f\"Final U-Net: {var_name.upper()} - Validation Time-Mean\",\n",
    "                        metric_val=mean_rmse_var_final_unet, metric_name=\"Time-Mean RMSE\")\n",
    "\n",
    "        pred_std_final_unet = pred_xr_final_unet.std(\"time\")\n",
    "        true_std_final_unet = true_xr_final_unet.std(\"time\")\n",
    "        std_mae_var_final_unet = np.abs(pred_std_final_unet - true_std_final_unet).weighted(area_weights_vis).mean().item()\n",
    "        plot_comparison(true_std_final_unet, pred_std_final_unet, \n",
    "                        f\"Final U-Net: {var_name.upper()} - Validation Time-StdDev\", cmap=\"plasma\",\n",
    "                        metric_val=std_mae_var_final_unet, metric_name=\"Time-StdDev MAE\")\n",
    "\n",
    "        if len(time_val_coords) > 0:\n",
    "            t_idx_random_final_unet = np.random.randint(0, len(time_val_coords))\n",
    "            pred_sample_final_unet = pred_xr_final_unet.isel(time=t_idx_random_final_unet)\n",
    "            true_sample_final_unet = true_xr_final_unet.isel(time=t_idx_random_final_unet)\n",
    "            sample_rmse_var_final_unet = np.sqrt(((pred_sample_final_unet - true_sample_final_unet) ** 2).weighted(area_weights_vis).mean()).item()\n",
    "            plot_comparison(true_sample_final_unet, pred_sample_final_unet, \n",
    "                            f\"Final U-Net: {var_name.upper()} - Validation Sample (Timestep {t_idx_random_final_unet})\",\n",
    "                            metric_val=sample_rmse_var_final_unet, metric_name=\"RMSE\")\n",
    "        else:\n",
    "            print(f\"No time steps available in validation predictions for {var_name} to plot a random sample.\")\n",
    "\n",
    "except NameError as e:\n",
    "    print(f\"NameError during U-Net final visualization: {e}. Ensure 'best_run_unet' was defined and the final training cell (Cell 18) ran successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"val_preds.npy or val_trues.npy not found for final U-Net run. \"\n",
    "          \"Ensure that the final U-Net training and validation (Cell 18) has run successfully.\")\n",
    "except AttributeError as e:\n",
    "    print(f\"AttributeError during final U-Net visualization: {e}. Ensure datamodule_final_unet is correctly initialized.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during final U-Net visualization: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70d7525-d12e-4a72-bc9a-b54e17d4c9c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
